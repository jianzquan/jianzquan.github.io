<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello Hexo</title>
    <url>/2024/05/01/wish/hello-hexo/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<p>在服务器上配置环境: </p>
<ul>
<li>sudo apt install nodejs</li>
<li>sudo apt install npm</li>
<li>sudo npm install hexo-cli -g</li>
</ul>
<p>进入项目文件夹:</p>
<ul>
<li>hexo init blog</li>
<li>cd blog&#x2F;</li>
<li>npm install</li>
<li>hexo s</li>
</ul>
<p>推送到GitHub:</p>
<ul>
<li>新建仓库 jianzquan.github.io</li>
<li>更改 _config.yml 文件</li>
<li>hexo clean &#x2F; hexo g &#x2F; hexo d</li>
</ul>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Hidden Markov Model</title>
    <url>/2024/05/01/study/hmm/</url>
    <content><![CDATA[<h2 id="Hidden-Markov-Model"><a href="#Hidden-Markov-Model" class="headerlink" title="Hidden Markov Model"></a>Hidden Markov Model</h2><h3 id="符号"><a href="#符号" class="headerlink" title="符号"></a>符号</h3><ul>
<li>观测序列: $X&#x3D;{ x_{1}, …, x_{T} }$ (离散&#x2F;连续取值均可)</li>
<li>隐藏序列: $Z&#x3D;{ z_{1}, …, z_{T} }$ (每个$z_{i}$有N种离散取值)</li>
<li>模型参数: $\lambda&#x3D;(\pi, A, B)$</li>
</ul>
<h3 id="基本假设"><a href="#基本假设" class="headerlink" title="基本假设"></a>基本假设</h3><ul>
<li><p>齐次Markov假设: (t+1时刻 隐藏状态只与前一时刻隐藏状态相关) </p>
<p>$p(z_{t+1}|z_{t},…,z_{1},x_{t},…,x_{1})&#x3D;p(z_{t+1}|z_{t})$</p>
</li>
<li><p>观测独立假设: (t时刻 观测状态只与 t时刻 隐藏状态相关)</p>
<p>$p(x_{t}|z_{t},…,z_{1},x_{t-1},…,x_{1})&#x3D;p(x_{t}|z_{t})$</p>
</li>
</ul>
<h3 id="三个问题"><a href="#三个问题" class="headerlink" title="三个问题"></a>三个问题</h3><ul>
<li><p>Evaluation: (已知模型参数, 求概率最大的观测序列 $X$) </p>
<p>$p(X|\lambda)$ $\to$ Forward-Backward 算法</p>
</li>
<li><p>Learning: (已知观测序列, 求模型参数)</p>
<p>$\lambda&#x3D;argmax_{\lambda} \ p(X|\lambda)$ $\to$ EM 算法 </p>
</li>
<li><p>Decoding: (已知模型参数和观测序列, 求概率最大的隐藏序列)</p>
<p>$Z&#x3D;argmax_{Z} \ p(Z|X, \lambda)$ $\to$ Vierbi 算法</p>
<ol>
<li>Filter: $p(z_{t}|x_{1},…,x_{t})$</li>
<li>Predict: $p(z_{t+1}|x_{1},…,x_{t})$</li>
</ol>
</li>
</ul>
<div align=center><img src="https://cdn.jsdelivr.net/gh/jianzquan/Rep4MyPage/img/HMM.png" width="600"></div>
<br/>

<h3 id="Forward-Algorithm"><a href="#Forward-Algorithm" class="headerlink" title="Forward Algorithm"></a>Forward Algorithm</h3><p>$\alpha_{t}(i)&#x3D;p(x_{1},…,x_{t}, z_{t}&#x3D;q_{i}|\lambda)$ (t时刻, 给定前t个观测状态,隐藏状态为 $q_{i}$ 的概率)</p>
<p>$\alpha_{t+1}(j)&#x3D;\sum_{i&#x3D;1}^{N}b_{j}(x_{t})a_{ij} * \alpha_{t}(i)$</p>
<h3 id="Backward-Algorithm"><a href="#Backward-Algorithm" class="headerlink" title="Backward Algorithm"></a>Backward Algorithm</h3><p>$\beta_{t}(i)&#x3D;p(x_{t+1},…,x_{T}|z_{t}&#x3D;q_{i}, \lambda)$ (t时刻, 给定后续观测状态, 隐藏状态为 $q_{i}$ 的概率)</p>
<p>$\beta_{t}(i)&#x3D;\sum_{j&#x3D;1}^{N}b_{j}(x_{t+1})a_{ij} * \beta_{t+1}(j)$</p>
<h3 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h3><h4 id="Learning"><a href="#Learning" class="headerlink" title="Learning"></a>Learning</h4><ul>
<li><p>$\lambda&#x3D;argmax_{\lambda} \ p(X|\lambda)$</p>
<p>  $p(X|\lambda)&#x3D;\sum_{Z}p(Z,X|\lambda)&#x3D;\sum_{Z}p(X|Z,\lambda)p(Z|\lambda)$</p>
</li>
</ul>
<h4 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h4><ul>
<li><p>Decoding: </p>
<p>$Z&#x3D;argmax_{Z} \ p(Z|X, \lambda)$</p>
</li>
<li><p>Prob of evidence: </p>
<p>$p(X)$</p>
</li>
<li><p>Filtering: </p>
<p>$p(z_{t}|x_{1},…,x_{t})$</p>
</li>
<li><p>Smoothing: </p>
<p>$p(z_{t}|x_{1},…,x_{T})$</p>
</li>
<li><p>Prediction: </p>
<p> $\left{<br>   \begin{array}{l}<br> p(z_{t+1}|x_{1},…,x_{t}) \<br> p(x_{t+1}|x_{1},…,x_{t})<br>   \end{array}<br>\right.$</p>
</li>
</ul>
<!-- $$ \left\{
  \begin{array}{l}
    Learning: \lambda=argmax_{\lambda} \ p(X|\lambda) \\
    Inference 
      \left\{
        \begin{array}{l}
          Decoding: Z=argmax_{Z} \ p(Z|X, \lambda) \\
          Prob \ of \ evidence: p(X) \\
          Filtering: p(z_{t}|x_{1},...,x_{t}) \\
          Smoothing: p(z_{t}|x_{1},...,x_{T}) \\
          Prediction:
             \left\{ 
               \begin{array}{l}
                 p(z_{t+1}|x_{1},...,x_{t}) \\
                 p(x_{t+1}|x_{1},...,x_{t})
               \end{array}
            \right.
        \end{array}
      \right.
  \end{array}
\right. $$ -->
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title>摄像·相机拍照</title>
    <url>/2024/05/02/wish/skill/%E6%91%84%E5%83%8F.%E7%9B%B8%E6%9C%BA%E6%8B%8D%E7%85%A7/</url>
    <content><![CDATA[<h2 id="课程-1"><a href="#课程-1" class="headerlink" title="课程 1"></a>课程 1</h2><ul>
<li>D</li>
</ul>
]]></content>
      <categories>
        <category>wish</category>
        <category>skill</category>
        <category>skill.camera</category>
      </categories>
      <tags>
        <tag>wish.skill</tag>
      </tags>
  </entry>
  <entry>
    <title>摄像·手机拍照</title>
    <url>/2024/05/04/wish/skill/%E6%91%84%E5%83%8F.%E6%89%8B%E6%9C%BA%E6%8B%8D%E7%85%A7/</url>
    <content><![CDATA[<h2 id="课程-1"><a href="#课程-1" class="headerlink" title="课程 1"></a>课程 1</h2><ul>
<li>D</li>
</ul>
]]></content>
      <categories>
        <category>wish</category>
        <category>skill</category>
        <category>skill.camera</category>
      </categories>
      <tags>
        <tag>wish.skill</tag>
      </tags>
  </entry>
  <entry>
    <title>烹饪·加餐美食</title>
    <url>/2024/05/04/wish/skill/%E7%83%B9%E9%A5%AA.%E5%8A%A0%E9%A4%90%E7%BE%8E%E9%A3%9F/</url>
    <content><![CDATA[<h1 id="米饭怎么煮才好吃"><a href="#米饭怎么煮才好吃" class="headerlink" title="米饭怎么煮才好吃"></a>米饭怎么煮才好吃</h1><h2 id="准备材料"><a href="#准备材料" class="headerlink" title="准备材料"></a>准备材料</h2><ul>
<li>xxx</li>
</ul>
<h2 id="制作步骤及注意事项"><a href="#制作步骤及注意事项" class="headerlink" title="制作步骤及注意事项"></a>制作步骤及注意事项</h2><ul>
<li>xxx</li>
</ul>
]]></content>
      <categories>
        <category>wish</category>
        <category>skill</category>
        <category>skill.cooking</category>
      </categories>
      <tags>
        <tag>wish.skill</tag>
      </tags>
  </entry>
  <entry>
    <title>烹饪·家常美食</title>
    <url>/2024/05/03/wish/skill/%E7%83%B9%E9%A5%AA.%E5%AE%B6%E5%B8%B8%E7%BE%8E%E9%A3%9F/</url>
    <content><![CDATA[<h1 id="米饭怎么煮才好吃"><a href="#米饭怎么煮才好吃" class="headerlink" title="米饭怎么煮才好吃"></a>米饭怎么煮才好吃</h1><h2 id="准备材料"><a href="#准备材料" class="headerlink" title="准备材料"></a>准备材料</h2><ul>
<li>xxx</li>
</ul>
<h2 id="制作步骤及注意事项"><a href="#制作步骤及注意事项" class="headerlink" title="制作步骤及注意事项"></a>制作步骤及注意事项</h2><ul>
<li>xxx</li>
</ul>
]]></content>
      <categories>
        <category>wish</category>
        <category>skill</category>
        <category>skill.cooking</category>
      </categories>
      <tags>
        <tag>wish.skill</tag>
      </tags>
  </entry>
  <entry>
    <title>国内游·厦漳泉</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%86%85%E6%B8%B8.%E5%8E%A6%E6%BC%B3%E6%B3%89/</url>
    <content><![CDATA[<h1 id="体验项目"><a href="#体验项目" class="headerlink" title="体验项目"></a>体验项目</h1><blockquote>
<ul>
<li>鼓浪屿拍照计划</li>
</ul>
</blockquote>
<!-- | 效果图 | 实际图 |
|  ----  | ----  |
| <img align='left' src='\image\travel\china\fujian\gly.jpg'> | <img align='left' src='\image\travel\china\fujian\gly.jpg'> |  -->
<!-- | ![alt text](\image\travel\china\fujian\gly.jpg) | 单元格 | -->
<table>
    
    <tr style="background-color: #f7f7f7;">
        <td align='center'>效果图</td>
        <td align='left'>实际图</td>
    </tr>
    <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/gly.jpg" width="99%"></td> </tr>
    <tr> <td rowspan="6">coming soon ...</td> </tr>
    <!-- <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/zz_food.jpg" width="99%"></td> </tr> -->
</table>

<blockquote>
<p>漂流体验</p>
</blockquote>
<h1 id="游玩行程"><a href="#游玩行程" class="headerlink" title="游玩行程"></a>游玩行程</h1><h2 id="厦门·鼓浪屿"><a href="#厦门·鼓浪屿" class="headerlink" title="厦门·鼓浪屿"></a>厦门·鼓浪屿</h2><h3 id="Plan"><a href="#Plan" class="headerlink" title="Plan"></a>Plan</h3><blockquote>
<p><em><strong>路线</strong></em>: 三丘田码头 -&gt; 最美转角 -&gt; 龙头路小吃街 -&gt; 皓月园 -&gt; 菽庄花园 -&gt; 日光岩 -&gt; 美华沙滩 -&gt; 内厝澳码头 </p>
</blockquote>
<table>
    <!-- <tr  style="background-color: #eff3f5;">
        <th colspan="3" style="text-align:center">单元格合并</th>
    </tr > -->
    <!-- <tr style="background-color: #f7f7f7;">
        <td>单元格</td>
        <td>单元格</td>
        <td>单元格</td>  
    </tr>
    <tr>
        <td>单元格</td>
        <td rowspan="3">单元格合并行</td>
        <td rowspan="3">单元格合并行</td>
    </tr>
    <tr>
        <td>单元格</td>
    </tr>
    <tr>
        <td>单元格</td>
    </tr> -->
    
    <tr style="background-color: #f7f7f7;">
        <td align='center'>地图</td>
        <td align='left'>景点</td>
        <td align='left'>计划</td>  
    </tr>
    <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/gly_map.jpg" width="99%"></td> </tr>
    <tr> <td>最美转角</td> <td> 1. 最美转角拍照 x1; <br> 2. 晴天墙拍照 x1 <br> <br> <b>Note</b>: 早上去, 下午人超多 </td> </tr>
    <tr> <td>龙头路小吃街</td> <td> 1. 龙头鲨鱼丸; <br> <br> <b>Note</b>: 不去凑热闹也行 </td> </tr>
    <tr> <td>皓月园</td> <td> 1. 郑成功雕像; <br> <br> <b>Note</b>:  </td> </tr>
    <tr> <td>菽庄花园</td> <td> 1. 园林; <br> <br> <b>Note</b>: 苏州园林花园 </td> </tr>
    <tr> <td>日/月光岩</td> <td> 1. 俯瞰厦门全岛; <br> <br> <b>Note</b>: 日光岩人多, 去月光岩吧 </td> </tr>
</table>

<h3 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h3><p>coming soon …</p>
<h2 id="龙岩·森林水乡"><a href="#龙岩·森林水乡" class="headerlink" title="龙岩·森林水乡"></a>龙岩·森林水乡</h2><h3 id="Plan-1"><a href="#Plan-1" class="headerlink" title="Plan"></a>Plan</h3><blockquote>
<p><em><strong>路线</strong></em>: 厦门 -&gt; 龙岩 2h; 龙岩市区 -&gt; 森林水乡 40m<br><em><strong>门票</strong></em>: 全套票 298 (也许能258, 多找找), 包括: 门票 + 九溪庐漂流 + 森林飞跃 + 天际线滑车 + 射箭 + 小火车</p>
</blockquote>
<h4 id="Note"><a href="#Note" class="headerlink" title="Note:"></a>Note:</h4><ul>
<li>顺序: 射箭 - 步步惊心 - 森林飞跃 - 高空滑车 - 观光车去天际线滑车 - 观光车到森林牧场 - 步行沐光之城 - 观光车下山, 到漂流入口 - 悬崖小火车</li>
<li>漂流项目为主(14:00 - 16:00), 带手机防水袋、速干衣、防晒衣、水漂(结实点, 水枪没啥用)、毛巾、更换衣物等</li>
</ul>
<h3 id="Review-1"><a href="#Review-1" class="headerlink" title="Review"></a>Review</h3><p>coming soon …</p>
<h2 id="漳州·漳州古城"><a href="#漳州·漳州古城" class="headerlink" title="漳州·漳州古城"></a>漳州·漳州古城</h2><h3 id="Plan-2"><a href="#Plan-2" class="headerlink" title="Plan"></a>Plan</h3><blockquote>
<p><em><strong>主题</strong></em>：逛吃… 逛吃…<br><em><strong>自驾</strong></em>：新华立体停车场; 侨乡停车场(逆行路线)</p>
</blockquote>
<table>
    
    <tr style="background-color: #f7f7f7;">
        <td align='center'>地图</td>
        <td align='left'>逛吃</td>
    </tr>
    <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/zz_map.jpg" width="99%"></td> </tr>
    <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/zz_food.jpg" width="99%"></td> </tr>
</table>

<h3 id="Review-2"><a href="#Review-2" class="headerlink" title="Review"></a>Review</h3><p>coming soon …</p>
<h2 id="泉州·泉州古城"><a href="#泉州·泉州古城" class="headerlink" title="泉州·泉州古城"></a>泉州·泉州古城</h2><h3 id="Plan-3"><a href="#Plan-3" class="headerlink" title="Plan"></a>Plan</h3><blockquote>
<p><em><strong>主题</strong></em>：体验历史<br><em><strong>自驾</strong></em>：</p>
</blockquote>
<table>
    
    <tr style="background-color: #f7f7f7;">
        <td align='center'>地图</td>
        <td align='left'>xxx</td>
    </tr>
    <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/qz_map.jpg" width="99%"></td> </tr>
    <tr> <td rowspan="6">coming soon ...</td> </tr>
</table>

<h3 id="Review-3"><a href="#Review-3" class="headerlink" title="Review"></a>Review</h3><p>coming soon …</p>
]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
        <category>travel.china</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>国内游.哈尔滨</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%86%85%E6%B8%B8.%E5%93%88%E5%B0%94%E6%BB%A8/</url>
    <content><![CDATA[<h1 id="体验项目"><a href="#体验项目" class="headerlink" title="体验项目"></a>体验项目</h1><blockquote>
<ul>
<li><p><em><strong>滑雪</strong></em>：x</p>
</li>
<li><p><em><strong>滑冰</strong></em>：xx</p>
</li>
</ul>
</blockquote>
<hr>
<h1 id="游玩行程"><a href="#游玩行程" class="headerlink" title="游玩行程"></a>游玩行程</h1><h2 id="1-哈尔滨"><a href="#1-哈尔滨" class="headerlink" title="1. 哈尔滨"></a>1. 哈尔滨</h2><p>xx</p>
]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
        <category>travel.china</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>国内游.五岳</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%86%85%E6%B8%B8.%E4%BA%94%E5%B2%B3/</url>
    <content><![CDATA[<h1 id="重点信息"><a href="#重点信息" class="headerlink" title="重点信息"></a>重点信息</h1><h2 id="事前准备"><a href="#事前准备" class="headerlink" title="事前准备"></a>事前准备</h2><table>
    <!--  -->
    <tr style="background-color: #f7f7f7;">
        <td align='center'>地图</td>
        <td align='center'>装备</td>
    </tr>
    <tr> <td rowspan="9"><img align='center' src="/image/travel/china/wuyue/locations.jpg" width="90%"></td> </tr>
    <tr> <td> 1. <strong>必带:</strong> 移动电源、身份证、学生证 </td> </tr>
    <tr> <td> 2. <strong>衣物:</strong> 登山鞋、冲锋衣、速干衣裤、手套、帽子、墨镜、护膝 </td> </tr>
    <tr> <td> 3. <strong>饮料:</strong> 矿泉水(大)(或景区购买)、电解质饮料 </td> </tr>
    <tr> <td> 4. <strong>食物:</strong> 巧克力、牛肉干、能量棒、坚果、水果 </td> </tr>
    <tr> <td> 5. <strong>工具:</strong> 登山包(背负系统)、登山杖、运动手表、保温杯、拍立得 </td> </tr>
    <tr> <td> 6. <strong>药物:</strong> 急救包、创口贴、藿香正气水、 </td> </tr>
    <tr> <td> 7. <strong>用品:</strong> 纸巾、口香糖、一次性毛巾、一次性雨衣 </td> </tr>
    <tr> <td> <strong>备注:</strong> 南岳衡山作为最后一站, 直接领取五岳奖牌 </td> </tr>
</table>

<h2 id="门票价格"><a href="#门票价格" class="headerlink" title="门票价格"></a>门票价格</h2><table>
<thead>
<tr>
<th>三山五岳</th>
<th>海拔</th>
<th>开放时间</th>
<th>门票价格</th>
<th>索道时间</th>
<th>索道价格</th>
</tr>
</thead>
<tbody><tr>
<td>北岳恒山</td>
<td>2016.1m</td>
<td>8:00-17:30</td>
<td>￥45</td>
<td>8:00-16:30</td>
<td>￥70</td>
</tr>
<tr>
<td>东岳泰山</td>
<td>1545m</td>
<td>5:00-24:00</td>
<td>￥115</td>
<td>中天门-南天门: 7:30-17:00 <br> 桃花源-南天门: 8:00-16:30</td>
<td>￥100</td>
</tr>
<tr>
<td>中岳嵩山</td>
<td>1491.7m</td>
<td>8:00-17:00</td>
<td>￥30</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>西岳华山</td>
<td>2154.9m</td>
<td>0:00-24:00</td>
<td>￥160</td>
<td>北峰索道: 6:40-19:00 <br> 西峰索道: 7:00-19:00</td>
<td>西峰: ￥140 <br> 北峰: ￥80</td>
</tr>
<tr>
<td>南岳衡山</td>
<td>1300.2m</td>
<td>7:30-17:30</td>
<td>￥80</td>
<td>南天门-半山亭: 7:00-17:30</td>
<td>￥44</td>
</tr>
</tbody></table>
<h2 id="计划安排"><a href="#计划安排" class="headerlink" title="计划安排"></a>计划安排</h2><h3 id="南岳衡山-最后一站-直接领奖牌"><a href="#南岳衡山-最后一站-直接领奖牌" class="headerlink" title="南岳衡山 (最后一站, 直接领奖牌)"></a>南岳衡山 (最后一站, 直接领奖牌)</h3><table>
<thead>
<tr>
<th>时间</th>
<th>计划</th>
<th>类型</th>
<th>预算</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>8:00-8:30</td>
<td>南岳大巴：衡山站-&gt;衡山风景区</td>
<td>交通</td>
<td>8.00</td>
<td></td>
</tr>
<tr>
<td>单元格</td>
<td>单元格</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>衡山攻略……</p>
<h3 id="中岳嵩山"><a href="#中岳嵩山" class="headerlink" title="中岳嵩山"></a>中岳嵩山</h3><p>嵩山攻略……</p>
<h3 id="东岳泰山"><a href="#东岳泰山" class="headerlink" title="东岳泰山"></a>东岳泰山</h3><p>日出东方，夜爬泰山看日出</p>
<h3 id="北岳恒山"><a href="#北岳恒山" class="headerlink" title="北岳恒山"></a>北岳恒山</h3><p>恒山攻略……</p>
<h3 id="西岳华山"><a href="#西岳华山" class="headerlink" title="西岳华山"></a>西岳华山</h3><p>华山攻略……</p>
]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>国内游.西安</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%86%85%E6%B8%B8.%E8%A5%BF%E5%AE%89/</url>
    <content><![CDATA[<h1 id="大唐不夜城"><a href="#大唐不夜城" class="headerlink" title="大唐不夜城"></a>大唐不夜城</h1><p>xxx</p>
]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>国内游.西藏</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%86%85%E6%B8%B8.%E8%A5%BF%E8%97%8F/</url>
    <content><![CDATA[<h1 id="体验项目"><a href="#体验项目" class="headerlink" title="体验项目"></a>体验项目</h1><blockquote>
<ul>
<li>自驾5000公里</li>
</ul>
</blockquote>
<h1 id="游玩行程"><a href="#游玩行程" class="headerlink" title="游玩行程"></a>游玩行程</h1><h2 id="厦门出发"><a href="#厦门出发" class="headerlink" title="厦门出发"></a>厦门出发</h2><h2 id="成都出发"><a href="#成都出发" class="headerlink" title="成都出发"></a>成都出发</h2><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul>
<li>预防高反</li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
        <category>travel.china</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>Large Language Models</title>
    <url>/2024/05/01/study/llm/llm/</url>
    <content><![CDATA[<h2 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h2><h3 id="source-https-github-com-RUCAIBox-Top-conference-paper-list-blob-main-EMNLP2022-ICLR2023-LLM-papers-md"><a href="#source-https-github-com-RUCAIBox-Top-conference-paper-list-blob-main-EMNLP2022-ICLR2023-LLM-papers-md" class="headerlink" title="source: https://github.com/RUCAIBox/Top-conference-paper-list/blob/main/EMNLP2022_ICLR2023_LLM_papers.md"></a>source: <a href="https://github.com/RUCAIBox/Top-conference-paper-list/blob/main/EMNLP2022_ICLR2023_LLM_papers.md">https://github.com/RUCAIBox/Top-conference-paper-list/blob/main/EMNLP2022_ICLR2023_LLM_papers.md</a></h3><h1 id="Catalog-目录"><a href="#Catalog-目录" class="headerlink" title="Catalog(目录)"></a>Catalog(目录)</h1><ul>
<li><a href="#catalog%E7%9B%AE%E5%BD%95">Catalog(目录)</a><ul>
<li><a href="#training%E8%AE%AD%E7%BB%83">Training【训练】</a><ul>
<li><a href="#pre-training%E9%A2%84%E8%AE%AD%E7%BB%83">Pre-Training【预训练】</a></li>
<li><a href="#instruction-tuning%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83">Instruction Tuning【指令微调】</a></li>
</ul>
</li>
<li><a href="#utilization%E4%BD%BF%E7%94%A8">Utilization【使用】</a><ul>
<li><a href="#in-context-learning%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0">In-Context Learning【上下文学习】</a></li>
<li><a href="#chain-of-thought-prompting%E6%80%9D%E7%BB%B4%E9%93%BE%E6%8F%90%E7%A4%BA">Chain-of-Thought Prompting【思维链提示】</a></li>
<li><a href="#z%E5%8E%8B%E7%BC%A9">z【压缩】</a></li>
<li><a href="#others%E5%85%B6%E4%BB%96">Others【其他】</a></li>
</ul>
</li>
<li><a href="#application%E5%BA%94%E7%94%A8">Application【应用】</a><ul>
<li><a href="#multi-modal%E5%A4%9A%E6%A8%A1%E6%80%81">Multi-Modal【多模态】</a></li>
<li><a href="#code%E4%BB%A3%E7%A0%81">Code【代码】</a></li>
<li><a href="#retrieval%E6%A3%80%E7%B4%A2">Retrieval【检索】</a></li>
<li><a href="#text-generation%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90">Text Generation【文本生成】</a></li>
<li><a href="#others%E5%85%B6%E4%BB%96-1">Others【其他】</a></li>
</ul>
</li>
<li><a href="#analysis--evaluation%E5%88%86%E6%9E%90%E4%B8%8E%E8%AF%84%E6%B5%8B">Analysis &amp; Evaluation【分析与评测】</a></li>
</ul>
</li>
</ul>
<h2 id="Training【训练】"><a href="#Training【训练】" class="headerlink" title="Training【训练】"></a>Training【训练】</h2><h3 id="Pre-Training【预训练】"><a href="#Pre-Training【预训练】" class="headerlink" title="Pre-Training【预训练】"></a>Pre-Training【预训练】</h3><ul>
<li>UL2: Unifying Language Learning Paradigms</li>
<li>Learning to Grow Pretrained Models for Efficient Transformer Training</li>
<li>Efficient Large Scale Language Modeling with Mixtures of Experts</li>
<li>Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models</li>
<li>CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis</li>
<li>InCoder: A Generative Model for Code Infilling and Synthesis</li>
<li>CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code</li>
<li>CodeRetriever: A Large Scale Contrastive Pre-Training Method for Code Search</li>
<li>UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining</li>
<li>GLM-130B: An Open Bilingual Pre-trained Model</li>
<li>When FLUE Meets FLANG: Benchmarks and Large Pretrained Language Model for Financial Domain</li>
</ul>
<h3 id="Instruction-Tuning【指令微调】"><a href="#Instruction-Tuning【指令微调】" class="headerlink" title="Instruction Tuning【指令微调】"></a>Instruction Tuning【指令微调】</h3><ul>
<li>What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment</li>
<li>InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning</li>
<li>Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization</li>
<li>Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks</li>
<li>Boosting Natural Language Generation from Instructions with Meta-Learning</li>
<li>Help me write a Poem - Instruction Tuning as a Vehicle for Collaborative Poetry Writing</li>
<li>Multitask Instruction-based Prompting for Fallacy Recognition</li>
<li>Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization</li>
<li>HypeR: Multitask Hyper-Prompted Training Enables Large-Scale Retrieval Generalization</li>
</ul>
<h2 id="Utilization【使用】"><a href="#Utilization【使用】" class="headerlink" title="Utilization【使用】"></a>Utilization【使用】</h2><h3 id="In-Context-Learning【上下文学习】"><a href="#In-Context-Learning【上下文学习】" class="headerlink" title="In-Context Learning【上下文学习】"></a>In-Context Learning【上下文学习】</h3><ul>
<li>​​What learning algorithm is in-context learning? Investigations with linear models</li>
<li>Ask Me Anything: A simple strategy for prompting language models</li>
<li>Large Language Models are Human-Level Prompt Engineers</li>
<li>Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks</li>
<li>kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference</li>
<li>Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners</li>
<li>Selective Annotation Makes Language Models Better Few-Shot Learners</li>
<li>Active Example Selection for In-Context Learning</li>
<li>Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?</li>
<li>In-Context Learning for Few-Shot Dialogue State Tracking</li>
<li>Few-Shot Anaphora Resolution in Scientific Protocols via Mixtures of In-Context Experts</li>
<li>ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback</li>
<li>Controllable Dialogue Simulation with In-context Learning</li>
<li>Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again</li>
<li>XRICL: Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing</li>
<li>On the Compositional Generalization Gap of In-Context Learning</li>
<li>Towards In-Context Non-Expert Evaluation of Reflection Generation for Counselling Conversations</li>
<li>Towards Few-Shot Identification of Morality Frames using In-Context Learning</li>
</ul>
<h3 id="Chain-of-Thought-Prompting【思维链提示】"><a href="#Chain-of-Thought-Prompting【思维链提示】" class="headerlink" title="Chain-of-Thought Prompting【思维链提示】"></a>Chain-of-Thought Prompting【思维链提示】</h3><ul>
<li>ReAct: Synergizing Reasoning and Acting in Language Models</li>
<li>Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning</li>
<li>Neuro-Symbolic Procedural Planning with Commonsense Prompting</li>
<li>Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought</li>
<li>PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales</li>
<li>Decomposed Prompting: A Modular Approach for Solving Complex Tasks</li>
<li>Complexity-Based Prompting for Multi-step Reasoning</li>
<li>Automatic Chain of Thought Prompting in Large Language Models</li>
<li>Compositional Semantic Parsing with Large Language Models</li>
<li>Self-Consistency Improves Chain of Thought Reasoning in Language Models</li>
<li>Least-to-Most Prompting Enables Complex Reasoning in Large Language Models</li>
<li>Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning</li>
<li>Iteratively Prompt Pre-trained Language Models for Chain of Thought</li>
<li>ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering</li>
<li>Induced Natural Language Rationales and Interleaved Markup Tokens Enable Extrapolation in Large Language Models</li>
</ul>
<h3 id="z【压缩】"><a href="#z【压缩】" class="headerlink" title="z【压缩】"></a>z【压缩】</h3><ul>
<li>Understanding and Improving Knowledge Distillation for Quantization Aware Training of Large Transformer Encoders</li>
<li>The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models</li>
<li>AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of Large-Scale Pre-Trained Language Models</li>
</ul>
<h3 id="Others【其他】"><a href="#Others【其他】" class="headerlink" title="Others【其他】"></a>Others【其他】</h3><ul>
<li>BBTv2: Towards a Gradient-Free Future with Large Language Models</li>
<li>Compositional Task Representations for Large Language Models</li>
<li>Just Fine-tune Twice: Selective Differential Privacy for Large Language Models</li>
</ul>
<h2 id="Application【应用】"><a href="#Application【应用】" class="headerlink" title="Application【应用】"></a>Application【应用】</h2><h3 id="Multi-Modal【多模态】"><a href="#Multi-Modal【多模态】" class="headerlink" title="Multi-Modal【多模态】"></a>Multi-Modal【多模态】</h3><ul>
<li>Visual Classification via Description from Large Language Models</li>
<li>Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language</li>
<li>Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training</li>
</ul>
<h3 id="Code【代码】"><a href="#Code【代码】" class="headerlink" title="Code【代码】"></a>Code【代码】</h3><ul>
<li>DocPrompting: Generating Code by Retrieving the Docs</li>
<li>Planning with Large Language Models for Code Generation</li>
<li>CodeT: Code Generation with Generated Tests</li>
<li>Language Models Can Teach Themselves to Program Better</li>
</ul>
<h3 id="Retrieval【检索】"><a href="#Retrieval【检索】" class="headerlink" title="Retrieval【检索】"></a>Retrieval【检索】</h3><ul>
<li>Promptagator: Few-shot Dense Retrieval From 8 Examples</li>
<li>Recitation-Augmented Language Models</li>
<li>Generate rather than Retrieve: Large Language Models are Strong Context Generators</li>
<li>QUILL: Query Intent with Large Language Models using Retrieval Augmentation and Multi-stage Distillation</li>
</ul>
<h3 id="Text-Generation【文本生成】"><a href="#Text-Generation【文本生成】" class="headerlink" title="Text Generation【文本生成】"></a>Text Generation【文本生成】</h3><ul>
<li>Generating Sequences by Learning to Self-Correct</li>
<li>RankGen: Improving Text Generation with Large Ranking Models</li>
<li>Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation</li>
</ul>
<h3 id="Others【其他】-1"><a href="#Others【其他】-1" class="headerlink" title="Others【其他】"></a>Others【其他】</h3><ul>
<li>Systematic Rectification of Language Models via Dead-end Analysis</li>
<li>Reward Design with Language Models</li>
<li>Bidirectional Language Models Are Also Few-shot Learners</li>
<li>Composing Ensembles of Pre-trained Models via Iterative Consensus</li>
<li>Binding Language Models in Symbolic Languages</li>
<li>Mind’s Eye: Grounded Language Model Reasoning through Simulation</li>
</ul>
<h2 id="Analysis-Evaluation【分析与评测】"><a href="#Analysis-Evaluation【分析与评测】" class="headerlink" title="Analysis &amp; Evaluation【分析与评测】"></a>Analysis &amp; Evaluation【分析与评测】</h2><ul>
<li>WikiWhy: Answering and Explaining Cause-and-Effect Questions</li>
<li>ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning</li>
<li>Quantifying Memorization Across Neural Language Models</li>
<li>Mass-Editing Memory in a Transformer</li>
<li>Multi-lingual Evaluation of Code Generation Models</li>
<li>STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK</li>
<li>Leveraging Large Language Models for Multiple Choice Question Answering</li>
<li>Broken Neural Scaling Laws</li>
<li>Language models are multilingual chain-of-thought reasoners</li>
<li>Language Models are Realistic Tabular Data Generators</li>
<li>Task Ambiguity in Humans and Language Models</li>
<li>Discovering Latent Knowledge in Language Models Without Supervision</li>
<li>Prompting GPT-3 To Be Reliable</li>
<li>Large language models are few-shot clinical information extractors</li>
<li>How Large Language Models are Transforming Machine-Paraphrase Plagiarism</li>
<li>Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs</li>
<li>SLING: Sino Linguistic Evaluation of Large Language Models</li>
<li>A Systematic Investigation of Commonsense Knowledge in Large Language Models</li>
<li>Lexical Generalization Improves with Larger Models and Longer Training</li>
<li>What do Large Language Models Learn beyond Language?</li>
<li>Probing for Understanding of English Verb Classes and Alternations in Large Pre-trained Language Models</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
        <category>llm</category>
      </categories>
      <tags>
        <tag>study.llm</tag>
      </tags>
  </entry>
  <entry>
    <title>国外游.新加坡</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%A4%96%E6%B8%B8.%E6%96%B0%E5%8A%A0%E5%9D%A1/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>Modality Large Language Model</title>
    <url>/2024/05/01/study/llm/mllm/</url>
    <content><![CDATA[<h2 id="1-语言模型发展阶段"><a href="#1-语言模型发展阶段" class="headerlink" title="1. 语言模型发展阶段"></a>1. 语言模型发展阶段</h2><p>This is MLLM Technique</p>
]]></content>
      <categories>
        <category>study</category>
        <category>llm</category>
      </categories>
      <tags>
        <tag>study.llm</tag>
      </tags>
  </entry>
  <entry>
    <title>Prompt-Tuning</title>
    <url>/2024/05/01/study/llm/prompt/</url>
    <content><![CDATA[<h2 id="1-语言模型发展阶段"><a href="#1-语言模型发展阶段" class="headerlink" title="1. 语言模型发展阶段"></a>1. 语言模型发展阶段</h2><ul>
<li><p><strong>第一阶段</strong>: Task-specific Fine-tuning</p>
<p>  <em><strong>过程</strong></em>：对于具体任务，以预训练语言模型为backbone，引入额外参数适配任务，进行fine-tuning。</p>
<p>  <em><strong>问题</strong></em>：① 下游任务目标与预训练目标差距过大；② 微调依赖大量监督语料</p>
<p>  <em><strong>代表</strong></em>：BERT、GPT、XLNet</p>
</li>
<li><p><strong>第二阶段</strong>: Prompt-tuning</p>
<p>  <em><strong>过程</strong></em>：逐步扩⼤模型参数和训练语料规模，探索不同类型的架构。</p>
<p>  <em><strong>代表</strong></em>：BART、T5、GPT-3等；</p>
</li>
<li><p><strong>第三阶段</strong>: </p>
<p>  <em><strong>过程</strong></em>：⾛向AIGC（Artificial Intelligent Generated Content）时代，模型参数规模步⼊千万亿，模型架构为⾃回归架构，⼤模型⾛向对话式、⽣成式、多模态时代，更加注重与⼈类交互进⾏对⻬，实现可靠、安全、⽆毒的模型。</p>
<p>  <em><strong>代表</strong></em>：InstructionGPT、Cha tGPT、Bard、GPT-4等。</p>
</li>
</ul>
<div align=center><img src="https://cdn.jsdelivr.net/gh/jianzquan/Rep4MyPage/img/LLM.jpg" width="800"></div>
<br/>


<h2 id="2-Prompt-Tuning"><a href="#2-Prompt-Tuning" class="headerlink" title="2. Prompt-Tuning"></a>2. Prompt-Tuning</h2><p>prompt-tuning 起源于GPT-3，GPT-3开创性地提出了in-context learning&#x2F;demonstrate learning，由于其是建立在大规模预训练语言模型上的，参数量大于10B，在真实场景中很难应用。这套方法应用在小模型上，就是prompt-tuning了。</p>
<p>prompt-tuning 旨在解决传统fine-tuning的两个痛点问题：</p>
<ul>
<li><em><strong>降低语义差异</strong></em>：缩小pre-training与fine-tuning两个阶段目标差距。</li>
<li><em><strong>避免过拟合</strong></em>：通过添加模板的方式避免引入额外的参数，进而造成的过拟合问题。<br/></li>
</ul>
<p>Prompt-tuning 两个关键问题：（还有Ensembling的玩法）</p>
<ul>
<li><p>模板构建(template): (大量优化方法)</p>
<p>人工构建</p>
<p>启发式发：PTR、AutoPrompt</p>
<p>生成：LM-BFF、</p>
<p>词向量微调</p>
<p>伪标记：Prompt Tuning、P-tuning、Pre-trained Prompt Tuning、</p>
</li>
<li><p>标签词映射(label word verbilizer): KPT、ProtoVerb、</p>
</li>
</ul>
<div align=center><img src="https://cdn.jsdelivr.net/gh/jianzquan/Rep4MyPage/img/Prompt.jpg" width="800"></div>

<br/>

<h2 id="3-面向LLM的Prompt-Tuning"><a href="#3-面向LLM的Prompt-Tuning" class="headerlink" title="3. 面向LLM的Prompt-Tuning"></a>3. 面向LLM的Prompt-Tuning</h2><p>研究发现，对于超过10亿参数量的模型来说。Prompt-tuning所带来的收益远远高于标准的Fine-tuning。</p>
<p>参数量够大、语料足够多、预训练任务足够有效，就能很好的实现免参数训练的零样本学习。</p>
<p>LLM的Prompt-tuning方法：</p>
<ul>
<li><p><strong>In-Context Learning</strong>: (研究论文&#x2F;技术很多很多)</p>
<p>  <em><strong>过程</strong></em>：从训练集中挑选少量的标注样本，设计任务相关的指令形成提示模板，用于指导测试样本生成相应的结果。</p>
  <div align=center><img src="https://cdn.jsdelivr.net/gh/jianzquan/Rep4MyPage/img/ICT.jpg" width="700"></div>
  
<p>  <em><strong>问题</strong></em>：如何选择样本？如何组合样本？(方差大、不稳定问题)</p>
</li>
<li><p><strong>Instruction-tuning</strong>:</p>
<p>  <em><strong>过程</strong></em>：为各种任务定义指令，按指令模板重构输入进行训练。</p>
</li>
<li><p><strong>Chain-of-Thought</strong>: 进一步提高超大模型在复杂任务上的推理能力。</p>
<p>  <em><strong>过程</strong></em>：代码的预训练</p>
</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
        <category>llm</category>
      </categories>
      <tags>
        <tag>study.llm</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM.Tuning</title>
    <url>/2024/05/25/study/llm/adapter/</url>
    <content><![CDATA[<div align=center><img src="/image/study/llm/peft.jpg" width="800"></div> <br>

<p>Thanks to: <a href="https://zhuanlan.zhihu.com/p/675231376">https://zhuanlan.zhihu.com/p/675231376</a><br>Library: <a href="https://github.com/adapter-hub/adapters">https://github.com/adapter-hub/adapters</a></p>
<h2 id="Fine-Tuning"><a href="#Fine-Tuning" class="headerlink" title="Fine-Tuning"></a>Fine-Tuning</h2><ul>
<li>调整 PLM&#x2F;LLM 所有层和参数, 使其适应特定任务.</li>
<li>使用较小的学习率 &amp; 特定任务的数据进行.</li>
<li>优点: 充分利用预训练模型的通用特征; 缺点: 需要更多的计算资源.</li>
</ul>
<h2 id="Parameter-Efficient-Fine-Tuning"><a href="#Parameter-Efficient-Fine-Tuning" class="headerlink" title="Parameter Efficient Fine-Tuning"></a>Parameter Efficient Fine-Tuning</h2><ul>
<li>最小化微调参数的数量和计算复杂度, 极大降低训练成本.</li>
<li>不改变 PLM&#x2F;LLM 知识前提下, 迅速适应新任务，实现高效的迁移学习.</li>
<li>提高模型效果的同时, 大大缩短模型训练时间和计算成本</li>
</ul>
<table>
    <tr style="background-color: #f7f7f7;">
        <td align='center'>Methods</td>
        <td align='center'>Principle</td>
    </tr>
    <tr> 
        <td> 
            <strong> 1. [LoRA](https://arxiv.org/abs/2106.09685): </strong> 
            <br> 1. 好，很好，非常好 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
    <tr> 
        <td> 
            <strong> 2. QLoRA: </strong> 
            <br> 1. 好，很好，非常好 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
    <tr> 
        <td> 
            <strong> 3. Adapter Tuning: </strong> 
            <br> 1. 好，很好，非常好 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
    <tr> 
        <td> 
            <strong> 4. Prefix Tuning: </strong> 
            <br> 1. 好，很好，非常好 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
    <tr> 
        <td> 
            <strong> 5. Prompt Tuning: </strong> 
            <br> * 好，很好，非常好 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
    <tr> 
        <td> 
            <strong> 6. P Tuning & v2: </strong> 
            <br> 1. 好，很好，非常好 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
</table>


<h3 id="Low-Rank-Adaptation-LoRA"><a href="#Low-Rank-Adaptation-LoRA" class="headerlink" title="Low-Rank Adaptation (LoRA)"></a><a href="https://arxiv.org/abs/2106.09685">Low-Rank Adaptation (LoRA)</a></h3><ul>
<li>123</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
        <category>llm</category>
      </categories>
      <tags>
        <tag>study.llm</tag>
      </tags>
  </entry>
  <entry>
    <title>CCM for ERC</title>
    <url>/2024/06/17/study/papers/ERC_CCM/</url>
    <content><![CDATA[<h2 align="center"> <a href="https://ieeexplore.ieee.org/abstract/document/10446226">Conversation Clique-based Model for Emotion Recognition in Conversation</a></h2>
<h5 align="center"> If you appreciate our project, please consider giving us a star ⭐ on GitHub to stay updated with the latest developments.  </h2>

<h4 align="center">

<p>🚀 Welcome to the repo of <a href="https://github.com/jian-projects/ccm"><strong>CCM</strong></a>!</p>
<p>CCM addresses the unimodal ERC task by modeling information with a conversation clique, accepted by ICASSP2024.</p>
<!-- [![🤗Hugging Face](https://img.shields.io/badge/🤗Hugging_Face-Uni_MoE-yellow)](https://huggingface.co/Uni-MoE) -->
<!-- [![Project Page](https://img.shields.io/badge/Project_Page-Uni_MoE-blue)](https://uni-moe.github.io/) -->
<!-- [![Demo](https://img.shields.io/badge/Demo-Local-orange)](https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs/tree/master?tab=readme-ov-file#-demo-video)  -->
<!-- [![Paper](https://img.shields.io/badge/Paper-arxiv-yellow)](https://arxiv.org/abs/2405.11273) -->

<p><a href="https://scholar.google.com/citations?user=C1PWVBUAAAAJ&hl=zh-CN">Zhongquan Jian</a>, Jiajian Li, <a href="https://scholar.google.com/citations?hl=zh-CN&user=Szz3hSMAAAAJ">Junfeng Yao</a>, <a href="https://dblp.uni-trier.de/pid/99/3203.html">Meihong Wang</a>, <a href="https://dblp.uni-trier.de/pid/130/0742.html">Qingqiang Wu</a></p>
</h4>

<!-- ## 🌟 Structure

The model architecture of Uni-MoE is shown below. Three training stages contain: 1) Utilize pairs from different modalities and languages to build connectors that map these elements to a unified language space, establishing a foundation for multimodal understanding; 2) Develop modality-specific experts using cross-modal data to ensure deep understanding, preparing for a cohesive multi-expert model; 3) Incorporate multiple trained experts into LLMs and refine the unified multimodal model using the LoRA technique on mixed multimodal data.

<div align=center><img src="https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs/blob/master/model.png" height="100%" width="75%"/></div> -->

<h2 id="⚡️-Install"><a href="#⚡️-Install" class="headerlink" title="⚡️ Install"></a>⚡️ Install</h2><p>The following instructions are for Linux installation.<br>We would like to recommend the requirements as follows.</p>
<ul>
<li>Python &#x3D;&#x3D; 3.9.16</li>
<li>CUDA Version &gt;&#x3D; 11.7</li>
</ul>
<ol>
<li><p>Clone this repository and navigate to the ccm folder</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git git@github.com:jian-projects/ccm.git<br><span class="hljs-built_in">cd</span> ccm<br></code></pre></td></tr></table></figure>
</li>
<li><p>Install Package</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs Shell">conda create -n ccm python==3.9.16<br>conda activate ccm<br>pip install -r env.txt<br></code></pre></td></tr></table></figure></li>
</ol>
<!-- 3. Replace all the absolute pathnames '/path/to/' with your specific path to the Uni-MoE file
**(Including all the eval_x.py/inference_x.py/train_mem_x.py/data.py/demo.py files and config.json files from the model weights)** -->


<h2 id="🌈-How-to-train-and-inference"><a href="#🌈-How-to-train-and-inference" class="headerlink" title="🌈 How to train and inference"></a>🌈 How to train and inference</h2><ol>
<li><p>Make sure that all the weights are downloaded and the running environment is set correctly.</p>
</li>
<li><p>run the script:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python run_erc.py<br></code></pre></td></tr></table></figure></li>
</ol>
<!-- 2. run inference scripts [`inference_audio.sh`](https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs/blob/master/Uni_MoE/inference_audio.sh) and [`inference_speech.sh`](https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs/blob/master/Uni_MoE/inference_speech.sh) using ```bash inference_audio.sh``` ```bash inference_speech.sh``` or run the following commands to inference:
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /path/to/Uni_MoE<br>conda activate unimoe<br>python Uni_MoE_audio/inference_all.py<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /path/to/Uni_MoE<br>conda activate unimoe<br>python Uni_MoE_speech/inference_all.py<br></code></pre></td></tr></table></figure>
<p>To launch the online demo ( It is highly recommended to launch the demo with <a href="https://huggingface.co/VictorJsy/Uni-MoE-speech-v1.5">Uni-MoE-speech-v1.5</a> that need the basic parameters of <a href="https://huggingface.co/VictorJsy/Uni-MoE-speech-base-interval">Uni-MoE-speech-base-interval</a>), run:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /path/to/Uni_MoE<br>conda activate unimoe<br>python demo/demo.py<br>python demo/app.py<br>``` --&gt;<br><br><span class="hljs-comment">## Citation</span><br><br>If you find Uni-MoE useful <span class="hljs-keyword">for</span> your research and applications, please cite using this BibTeX:<br>```bibtex<br><br>@INPROCEEDINGS&#123;2024.erc.ccm,<br>  author=&#123;Jian, Zhongquan and Li, Jiajian and Yao, Junfeng and Wang, Meihong and Wu, Qingqiang&#125;,<br>  booktitle=&#123;ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)&#125;, <br>  title=&#123;Conversation Clique-Based Model <span class="hljs-keyword">for</span> Emotion Recognition In Conversation&#125;, <br>  year=&#123;2024&#125;,<br>  volume=&#123;&#125;,<br>  number=&#123;&#125;,<br>  pages=&#123;5865-5869&#125;,<br>  doi=&#123;10.1109/ICASSP48485.2024.10446226&#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>study</category>
        <category>study.paper</category>
      </categories>
      <tags>
        <tag>study.paper</tag>
      </tags>
  </entry>
  <entry>
    <title>Github 仓库配置</title>
    <url>/2024/06/16/study/skill/Github/</url>
    <content><![CDATA[<h2 align="center"> <a href="https://jianzquan.github.io/">Github 相关配置</a></h2>
<h5 align="center"> 1. 本地仓库链接Github仓库；2. 仓库更新操作；3. Github的VsCode配置 </h2>

<h4 align="center">

<p>Template Reference From <a href="https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs">Uni-MoE</a></p>
<h2 id="🎨-Github-Config"><a href="#🎨-Github-Config" class="headerlink" title="🎨 Github Config"></a>🎨 Github Config</h2><h3 id="For-Windows"><a href="#For-Windows" class="headerlink" title="For Windows"></a>For Windows</h3><ol>
<li><p>下载 <a href="https://github.com/git-for-windows/git/releases">Git</a>，并安装. 然后，配置Git的用户和邮箱:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git config --global user.name xxx<br>git config --global user.email xxxx<br></code></pre></td></tr></table></figure></li>
<li><p>本地公钥复制到 <a href="https://github.com/settings/keys">Github</a> 上. 创建仓库，复制仓库地址.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">ssh-keygen -t rsa (生成密钥对，Git操作，位置通常在&#x27;C:\用户\用户名\.ssh\&#x27;)<br></code></pre></td></tr></table></figure>
</li>
<li><p>首次将本地仓库链接到Github上.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git init (文件夹下出现 .git 隐藏文件)<br>git add README.md<br>git commit -m <span class="hljs-string">&quot;first commit&quot;</span><br>git branch -M main<br>git remote add origin 仓库地址<br>git push -u origin main<br></code></pre></td></tr></table></figure></li>
</ol>
<h3 id="For-Linux"><a href="#For-Linux" class="headerlink" title="For Linux"></a>For Linux</h3><p>Coming sooon</p>
<h2 id="📀-Repository-Update"><a href="#📀-Repository-Update" class="headerlink" title="📀 Repository Update"></a>📀 Repository Update</h2><ol>
<li><p>文件更新后，上传到github.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">git add 文件 (. 表示添加所有)<br>git commit -m &quot;xxx&quot;<br>git push (-f 表示强制覆盖远程文件)<br></code></pre></td></tr></table></figure>
</li>
<li><p>撤销提交状态.</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><code class="hljs pgsql">git <span class="hljs-keyword">reset</span> HEAD (撤销<span class="hljs-keyword">add</span>)<br>git <span class="hljs-keyword">reset</span> <span class="hljs-comment">--soft HEAD^ (仅撤销commit，保留add)</span><br></code></pre></td></tr></table></figure></li>
</ol>
<h2 id="🌟-VsCode-服务器免密"><a href="#🌟-VsCode-服务器免密" class="headerlink" title="🌟 VsCode 服务器免密"></a>🌟 VsCode 服务器免密</h2><ol>
<li><p>安装插件 Remote-SSH</p>
</li>
<li><p>本地公钥存放到远程服务器端</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh-copy-id 用户名@服务器地址 (Windows 上用 Git 操作)<br></code></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>study</category>
        <category>study.skill</category>
      </categories>
      <tags>
        <tag>study.skill</tag>
      </tags>
  </entry>
</search>
