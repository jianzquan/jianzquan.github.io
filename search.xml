<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello Hexo</title>
    <url>/2024/05/01/wish/hello-hexo/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<p>åœ¨æœåŠ¡å™¨ä¸Šé…ç½®ç¯å¢ƒ: </p>
<ul>
<li>sudo apt install nodejs</li>
<li>sudo apt install npm</li>
<li>sudo npm install hexo-cli -g</li>
</ul>
<p>è¿›å…¥é¡¹ç›®æ–‡ä»¶å¤¹:</p>
<ul>
<li>hexo init blog</li>
<li>cd blog&#x2F;</li>
<li>npm install</li>
<li>hexo s</li>
</ul>
<p>æ¨é€åˆ°GitHub:</p>
<ul>
<li>æ–°å»ºä»“åº“ jianzquan.github.io</li>
<li>æ›´æ”¹ _config.yml æ–‡ä»¶</li>
<li>hexo clean &#x2F; hexo g &#x2F; hexo d</li>
</ul>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Hidden Markov Model</title>
    <url>/2024/05/01/study/hmm/</url>
    <content><![CDATA[<h2 id="Hidden-Markov-Model"><a href="#Hidden-Markov-Model" class="headerlink" title="Hidden Markov Model"></a>Hidden Markov Model</h2><h3 id="ç¬¦å·"><a href="#ç¬¦å·" class="headerlink" title="ç¬¦å·"></a>ç¬¦å·</h3><ul>
<li>è§‚æµ‹åºåˆ—: $X&#x3D;{ x_{1}, â€¦, x_{T} }$ (ç¦»æ•£&#x2F;è¿ç»­å–å€¼å‡å¯)</li>
<li>éšè—åºåˆ—: $Z&#x3D;{ z_{1}, â€¦, z_{T} }$ (æ¯ä¸ª$z_{i}$æœ‰Nç§ç¦»æ•£å–å€¼)</li>
<li>æ¨¡å‹å‚æ•°: $\lambda&#x3D;(\pi, A, B)$</li>
</ul>
<h3 id="åŸºæœ¬å‡è®¾"><a href="#åŸºæœ¬å‡è®¾" class="headerlink" title="åŸºæœ¬å‡è®¾"></a>åŸºæœ¬å‡è®¾</h3><ul>
<li><p>é½æ¬¡Markovå‡è®¾: (t+1æ—¶åˆ» éšè—çŠ¶æ€åªä¸å‰ä¸€æ—¶åˆ»éšè—çŠ¶æ€ç›¸å…³) </p>
<p>$p(z_{t+1}|z_{t},â€¦,z_{1},x_{t},â€¦,x_{1})&#x3D;p(z_{t+1}|z_{t})$</p>
</li>
<li><p>è§‚æµ‹ç‹¬ç«‹å‡è®¾: (tæ—¶åˆ» è§‚æµ‹çŠ¶æ€åªä¸ tæ—¶åˆ» éšè—çŠ¶æ€ç›¸å…³)</p>
<p>$p(x_{t}|z_{t},â€¦,z_{1},x_{t-1},â€¦,x_{1})&#x3D;p(x_{t}|z_{t})$</p>
</li>
</ul>
<h3 id="ä¸‰ä¸ªé—®é¢˜"><a href="#ä¸‰ä¸ªé—®é¢˜" class="headerlink" title="ä¸‰ä¸ªé—®é¢˜"></a>ä¸‰ä¸ªé—®é¢˜</h3><ul>
<li><p>Evaluation: (å·²çŸ¥æ¨¡å‹å‚æ•°, æ±‚æ¦‚ç‡æœ€å¤§çš„è§‚æµ‹åºåˆ— $X$) </p>
<p>$p(X|\lambda)$ $\to$ Forward-Backward ç®—æ³•</p>
</li>
<li><p>Learning: (å·²çŸ¥è§‚æµ‹åºåˆ—, æ±‚æ¨¡å‹å‚æ•°)</p>
<p>$\lambda&#x3D;argmax_{\lambda} \ p(X|\lambda)$ $\to$ EM ç®—æ³• </p>
</li>
<li><p>Decoding: (å·²çŸ¥æ¨¡å‹å‚æ•°å’Œè§‚æµ‹åºåˆ—, æ±‚æ¦‚ç‡æœ€å¤§çš„éšè—åºåˆ—)</p>
<p>$Z&#x3D;argmax_{Z} \ p(Z|X, \lambda)$ $\to$ Vierbi ç®—æ³•</p>
<ol>
<li>Filter: $p(z_{t}|x_{1},â€¦,x_{t})$</li>
<li>Predict: $p(z_{t+1}|x_{1},â€¦,x_{t})$</li>
</ol>
</li>
</ul>
<div align=center><img src="https://cdn.jsdelivr.net/gh/jianzquan/Rep4MyPage/img/HMM.png" width="600"></div>
<br/>

<h3 id="Forward-Algorithm"><a href="#Forward-Algorithm" class="headerlink" title="Forward Algorithm"></a>Forward Algorithm</h3><p>$\alpha_{t}(i)&#x3D;p(x_{1},â€¦,x_{t}, z_{t}&#x3D;q_{i}|\lambda)$ (tæ—¶åˆ», ç»™å®šå‰tä¸ªè§‚æµ‹çŠ¶æ€,éšè—çŠ¶æ€ä¸º $q_{i}$ çš„æ¦‚ç‡)</p>
<p>$\alpha_{t+1}(j)&#x3D;\sum_{i&#x3D;1}^{N}b_{j}(x_{t})a_{ij} * \alpha_{t}(i)$</p>
<h3 id="Backward-Algorithm"><a href="#Backward-Algorithm" class="headerlink" title="Backward Algorithm"></a>Backward Algorithm</h3><p>$\beta_{t}(i)&#x3D;p(x_{t+1},â€¦,x_{T}|z_{t}&#x3D;q_{i}, \lambda)$ (tæ—¶åˆ», ç»™å®šåç»­è§‚æµ‹çŠ¶æ€, éšè—çŠ¶æ€ä¸º $q_{i}$ çš„æ¦‚ç‡)</p>
<p>$\beta_{t}(i)&#x3D;\sum_{j&#x3D;1}^{N}b_{j}(x_{t+1})a_{ij} * \beta_{t+1}(j)$</p>
<h3 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h3><h4 id="Learning"><a href="#Learning" class="headerlink" title="Learning"></a>Learning</h4><ul>
<li><p>$\lambda&#x3D;argmax_{\lambda} \ p(X|\lambda)$</p>
<p>  $p(X|\lambda)&#x3D;\sum_{Z}p(Z,X|\lambda)&#x3D;\sum_{Z}p(X|Z,\lambda)p(Z|\lambda)$</p>
</li>
</ul>
<h4 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h4><ul>
<li><p>Decoding: </p>
<p>$Z&#x3D;argmax_{Z} \ p(Z|X, \lambda)$</p>
</li>
<li><p>Prob of evidence: </p>
<p>$p(X)$</p>
</li>
<li><p>Filtering: </p>
<p>$p(z_{t}|x_{1},â€¦,x_{t})$</p>
</li>
<li><p>Smoothing: </p>
<p>$p(z_{t}|x_{1},â€¦,x_{T})$</p>
</li>
<li><p>Prediction: </p>
<p> $\left{<br>   \begin{array}{l}<br> p(z_{t+1}|x_{1},â€¦,x_{t}) \<br> p(x_{t+1}|x_{1},â€¦,x_{t})<br>   \end{array}<br>\right.$</p>
</li>
</ul>
<!-- $$ \left\{
  \begin{array}{l}
    Learning: \lambda=argmax_{\lambda} \ p(X|\lambda) \\
    Inference 
      \left\{
        \begin{array}{l}
          Decoding: Z=argmax_{Z} \ p(Z|X, \lambda) \\
          Prob \ of \ evidence: p(X) \\
          Filtering: p(z_{t}|x_{1},...,x_{t}) \\
          Smoothing: p(z_{t}|x_{1},...,x_{T}) \\
          Prediction:
             \left\{ 
               \begin{array}{l}
                 p(z_{t+1}|x_{1},...,x_{t}) \\
                 p(x_{t+1}|x_{1},...,x_{t})
               \end{array}
            \right.
        \end{array}
      \right.
  \end{array}
\right. $$ -->
]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title>æ‘„åƒÂ·ç›¸æœºæ‹ç…§</title>
    <url>/2024/05/02/wish/skill/%E6%91%84%E5%83%8F.%E7%9B%B8%E6%9C%BA%E6%8B%8D%E7%85%A7/</url>
    <content><![CDATA[<h2 id="è¯¾ç¨‹-1"><a href="#è¯¾ç¨‹-1" class="headerlink" title="è¯¾ç¨‹ 1"></a>è¯¾ç¨‹ 1</h2><ul>
<li>D</li>
</ul>
]]></content>
      <categories>
        <category>wish</category>
        <category>skill</category>
        <category>skill.camera</category>
      </categories>
      <tags>
        <tag>wish.skill</tag>
      </tags>
  </entry>
  <entry>
    <title>æ‘„åƒÂ·æ‰‹æœºæ‹ç…§</title>
    <url>/2024/05/04/wish/skill/%E6%91%84%E5%83%8F.%E6%89%8B%E6%9C%BA%E6%8B%8D%E7%85%A7/</url>
    <content><![CDATA[<h2 id="è¯¾ç¨‹-1"><a href="#è¯¾ç¨‹-1" class="headerlink" title="è¯¾ç¨‹ 1"></a>è¯¾ç¨‹ 1</h2><ul>
<li>D</li>
</ul>
]]></content>
      <categories>
        <category>wish</category>
        <category>skill</category>
        <category>skill.camera</category>
      </categories>
      <tags>
        <tag>wish.skill</tag>
      </tags>
  </entry>
  <entry>
    <title>çƒ¹é¥ªÂ·åŠ é¤ç¾é£Ÿ</title>
    <url>/2024/05/04/wish/skill/%E7%83%B9%E9%A5%AA.%E5%8A%A0%E9%A4%90%E7%BE%8E%E9%A3%9F/</url>
    <content><![CDATA[<h1 id="ç±³é¥­æ€ä¹ˆç…®æ‰å¥½åƒ"><a href="#ç±³é¥­æ€ä¹ˆç…®æ‰å¥½åƒ" class="headerlink" title="ç±³é¥­æ€ä¹ˆç…®æ‰å¥½åƒ"></a>ç±³é¥­æ€ä¹ˆç…®æ‰å¥½åƒ</h1><h2 id="å‡†å¤‡ææ–™"><a href="#å‡†å¤‡ææ–™" class="headerlink" title="å‡†å¤‡ææ–™"></a>å‡†å¤‡ææ–™</h2><ul>
<li>xxx</li>
</ul>
<h2 id="åˆ¶ä½œæ­¥éª¤åŠæ³¨æ„äº‹é¡¹"><a href="#åˆ¶ä½œæ­¥éª¤åŠæ³¨æ„äº‹é¡¹" class="headerlink" title="åˆ¶ä½œæ­¥éª¤åŠæ³¨æ„äº‹é¡¹"></a>åˆ¶ä½œæ­¥éª¤åŠæ³¨æ„äº‹é¡¹</h2><ul>
<li>xxx</li>
</ul>
]]></content>
      <categories>
        <category>wish</category>
        <category>skill</category>
        <category>skill.cooking</category>
      </categories>
      <tags>
        <tag>wish.skill</tag>
      </tags>
  </entry>
  <entry>
    <title>çƒ¹é¥ªÂ·å®¶å¸¸ç¾é£Ÿ</title>
    <url>/2024/05/03/wish/skill/%E7%83%B9%E9%A5%AA.%E5%AE%B6%E5%B8%B8%E7%BE%8E%E9%A3%9F/</url>
    <content><![CDATA[<h1 id="ç±³é¥­æ€ä¹ˆç…®æ‰å¥½åƒ"><a href="#ç±³é¥­æ€ä¹ˆç…®æ‰å¥½åƒ" class="headerlink" title="ç±³é¥­æ€ä¹ˆç…®æ‰å¥½åƒ"></a>ç±³é¥­æ€ä¹ˆç…®æ‰å¥½åƒ</h1><h2 id="å‡†å¤‡ææ–™"><a href="#å‡†å¤‡ææ–™" class="headerlink" title="å‡†å¤‡ææ–™"></a>å‡†å¤‡ææ–™</h2><ul>
<li>xxx</li>
</ul>
<h2 id="åˆ¶ä½œæ­¥éª¤åŠæ³¨æ„äº‹é¡¹"><a href="#åˆ¶ä½œæ­¥éª¤åŠæ³¨æ„äº‹é¡¹" class="headerlink" title="åˆ¶ä½œæ­¥éª¤åŠæ³¨æ„äº‹é¡¹"></a>åˆ¶ä½œæ­¥éª¤åŠæ³¨æ„äº‹é¡¹</h2><ul>
<li>xxx</li>
</ul>
]]></content>
      <categories>
        <category>wish</category>
        <category>skill</category>
        <category>skill.cooking</category>
      </categories>
      <tags>
        <tag>wish.skill</tag>
      </tags>
  </entry>
  <entry>
    <title>å›½å†…æ¸¸Â·å¦æ¼³æ³‰</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%86%85%E6%B8%B8.%E5%8E%A6%E6%BC%B3%E6%B3%89/</url>
    <content><![CDATA[<h1 id="ä½“éªŒé¡¹ç›®"><a href="#ä½“éªŒé¡¹ç›®" class="headerlink" title="ä½“éªŒé¡¹ç›®"></a>ä½“éªŒé¡¹ç›®</h1><blockquote>
<ul>
<li>é¼“æµªå±¿æ‹ç…§è®¡åˆ’</li>
</ul>
</blockquote>
<!-- | æ•ˆæœå›¾ | å®é™…å›¾ |
|  ----  | ----  |
| <img align='left' src='\image\travel\china\fujian\gly.jpg'> | <img align='left' src='\image\travel\china\fujian\gly.jpg'> |  -->
<!-- | ![alt text](\image\travel\china\fujian\gly.jpg) | å•å…ƒæ ¼ | -->
<table>
    
    <tr style="background-color: #f7f7f7;">
        <td align='center'>æ•ˆæœå›¾</td>
        <td align='left'>å®é™…å›¾</td>
    </tr>
    <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/gly.jpg" width="99%"></td> </tr>
    <tr> <td rowspan="6">coming soon ...</td> </tr>
    <!-- <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/zz_food.jpg" width="99%"></td> </tr> -->
</table>

<blockquote>
<p>æ¼‚æµä½“éªŒ</p>
</blockquote>
<h1 id="æ¸¸ç©è¡Œç¨‹"><a href="#æ¸¸ç©è¡Œç¨‹" class="headerlink" title="æ¸¸ç©è¡Œç¨‹"></a>æ¸¸ç©è¡Œç¨‹</h1><h2 id="å¦é—¨Â·é¼“æµªå±¿"><a href="#å¦é—¨Â·é¼“æµªå±¿" class="headerlink" title="å¦é—¨Â·é¼“æµªå±¿"></a>å¦é—¨Â·é¼“æµªå±¿</h2><h3 id="Plan"><a href="#Plan" class="headerlink" title="Plan"></a>Plan</h3><blockquote>
<p><em><strong>è·¯çº¿</strong></em>: ä¸‰ä¸˜ç”°ç å¤´ -&gt; æœ€ç¾è½¬è§’ -&gt; é¾™å¤´è·¯å°åƒè¡— -&gt; çš“æœˆå›­ -&gt; è½åº„èŠ±å›­ -&gt; æ—¥å…‰å²© -&gt; ç¾åæ²™æ»© -&gt; å†…åæ¾³ç å¤´ </p>
</blockquote>
<table>
    <!-- <tr  style="background-color: #eff3f5;">
        <th colspan="3" style="text-align:center">å•å…ƒæ ¼åˆå¹¶</th>
    </tr > -->
    <!-- <tr style="background-color: #f7f7f7;">
        <td>å•å…ƒæ ¼</td>
        <td>å•å…ƒæ ¼</td>
        <td>å•å…ƒæ ¼</td>  
    </tr>
    <tr>
        <td>å•å…ƒæ ¼</td>
        <td rowspan="3">å•å…ƒæ ¼åˆå¹¶è¡Œ</td>
        <td rowspan="3">å•å…ƒæ ¼åˆå¹¶è¡Œ</td>
    </tr>
    <tr>
        <td>å•å…ƒæ ¼</td>
    </tr>
    <tr>
        <td>å•å…ƒæ ¼</td>
    </tr> -->
    
    <tr style="background-color: #f7f7f7;">
        <td align='center'>åœ°å›¾</td>
        <td align='left'>æ™¯ç‚¹</td>
        <td align='left'>è®¡åˆ’</td>  
    </tr>
    <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/gly_map.jpg" width="99%"></td> </tr>
    <tr> <td>æœ€ç¾è½¬è§’</td> <td> 1. æœ€ç¾è½¬è§’æ‹ç…§ x1; <br> 2. æ™´å¤©å¢™æ‹ç…§ x1 <br> <br> <b>Note</b>: æ—©ä¸Šå», ä¸‹åˆäººè¶…å¤š </td> </tr>
    <tr> <td>é¾™å¤´è·¯å°åƒè¡—</td> <td> 1. é¾™å¤´é²¨é±¼ä¸¸; <br> <br> <b>Note</b>: ä¸å»å‡‘çƒ­é—¹ä¹Ÿè¡Œ </td> </tr>
    <tr> <td>çš“æœˆå›­</td> <td> 1. éƒ‘æˆåŠŸé›•åƒ; <br> <br> <b>Note</b>:  </td> </tr>
    <tr> <td>è½åº„èŠ±å›­</td> <td> 1. å›­æ—; <br> <br> <b>Note</b>: è‹å·å›­æ—èŠ±å›­ </td> </tr>
    <tr> <td>æ—¥/æœˆå…‰å²©</td> <td> 1. ä¿¯ç°å¦é—¨å…¨å²›; <br> <br> <b>Note</b>: æ—¥å…‰å²©äººå¤š, å»æœˆå…‰å²©å§ </td> </tr>
</table>

<h3 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h3><p>coming soon â€¦</p>
<h2 id="é¾™å²©Â·æ£®æ—æ°´ä¹¡"><a href="#é¾™å²©Â·æ£®æ—æ°´ä¹¡" class="headerlink" title="é¾™å²©Â·æ£®æ—æ°´ä¹¡"></a>é¾™å²©Â·æ£®æ—æ°´ä¹¡</h2><h3 id="Plan-1"><a href="#Plan-1" class="headerlink" title="Plan"></a>Plan</h3><blockquote>
<p><em><strong>è·¯çº¿</strong></em>: å¦é—¨ -&gt; é¾™å²© 2h; é¾™å²©å¸‚åŒº -&gt; æ£®æ—æ°´ä¹¡ 40m<br><em><strong>é—¨ç¥¨</strong></em>: å…¨å¥—ç¥¨ 298 (ä¹Ÿè®¸èƒ½258, å¤šæ‰¾æ‰¾), åŒ…æ‹¬: é—¨ç¥¨ + ä¹æºªåºæ¼‚æµ + æ£®æ—é£è·ƒ + å¤©é™…çº¿æ»‘è½¦ + å°„ç®­ + å°ç«è½¦</p>
</blockquote>
<h4 id="Note"><a href="#Note" class="headerlink" title="Note:"></a>Note:</h4><ul>
<li>é¡ºåº: å°„ç®­ - æ­¥æ­¥æƒŠå¿ƒ - æ£®æ—é£è·ƒ - é«˜ç©ºæ»‘è½¦ - è§‚å…‰è½¦å»å¤©é™…çº¿æ»‘è½¦ - è§‚å…‰è½¦åˆ°æ£®æ—ç‰§åœº - æ­¥è¡Œæ²å…‰ä¹‹åŸ - è§‚å…‰è½¦ä¸‹å±±, åˆ°æ¼‚æµå…¥å£ - æ‚¬å´–å°ç«è½¦</li>
<li>æ¼‚æµé¡¹ç›®ä¸ºä¸»(14:00 - 16:00), å¸¦æ‰‹æœºé˜²æ°´è¢‹ã€é€Ÿå¹²è¡£ã€é˜²æ™’è¡£ã€æ°´æ¼‚(ç»“å®ç‚¹, æ°´æªæ²¡å•¥ç”¨)ã€æ¯›å·¾ã€æ›´æ¢è¡£ç‰©ç­‰</li>
</ul>
<h3 id="Review-1"><a href="#Review-1" class="headerlink" title="Review"></a>Review</h3><p>coming soon â€¦</p>
<h2 id="æ¼³å·Â·æ¼³å·å¤åŸ"><a href="#æ¼³å·Â·æ¼³å·å¤åŸ" class="headerlink" title="æ¼³å·Â·æ¼³å·å¤åŸ"></a>æ¼³å·Â·æ¼³å·å¤åŸ</h2><h3 id="Plan-2"><a href="#Plan-2" class="headerlink" title="Plan"></a>Plan</h3><blockquote>
<p><em><strong>ä¸»é¢˜</strong></em>ï¼šé€›åƒâ€¦ é€›åƒâ€¦<br><em><strong>è‡ªé©¾</strong></em>ï¼šæ–°åç«‹ä½“åœè½¦åœº; ä¾¨ä¹¡åœè½¦åœº(é€†è¡Œè·¯çº¿)</p>
</blockquote>
<table>
    
    <tr style="background-color: #f7f7f7;">
        <td align='center'>åœ°å›¾</td>
        <td align='left'>é€›åƒ</td>
    </tr>
    <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/zz_map.jpg" width="99%"></td> </tr>
    <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/zz_food.jpg" width="99%"></td> </tr>
</table>

<h3 id="Review-2"><a href="#Review-2" class="headerlink" title="Review"></a>Review</h3><p>coming soon â€¦</p>
<h2 id="æ³‰å·Â·æ³‰å·å¤åŸ"><a href="#æ³‰å·Â·æ³‰å·å¤åŸ" class="headerlink" title="æ³‰å·Â·æ³‰å·å¤åŸ"></a>æ³‰å·Â·æ³‰å·å¤åŸ</h2><h3 id="Plan-3"><a href="#Plan-3" class="headerlink" title="Plan"></a>Plan</h3><blockquote>
<p><em><strong>ä¸»é¢˜</strong></em>ï¼šä½“éªŒå†å²<br><em><strong>è‡ªé©¾</strong></em>ï¼š</p>
</blockquote>
<table>
    
    <tr style="background-color: #f7f7f7;">
        <td align='center'>åœ°å›¾</td>
        <td align='left'>xxx</td>
    </tr>
    <tr> <td rowspan="6"><img align='left' src="/image/travel/china/fujian/qz_map.jpg" width="99%"></td> </tr>
    <tr> <td rowspan="6">coming soon ...</td> </tr>
</table>

<h3 id="Review-3"><a href="#Review-3" class="headerlink" title="Review"></a>Review</h3><p>coming soon â€¦</p>
]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
        <category>travel.china</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>å›½å†…æ¸¸.å“ˆå°”æ»¨</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%86%85%E6%B8%B8.%E5%93%88%E5%B0%94%E6%BB%A8/</url>
    <content><![CDATA[<h1 id="ä½“éªŒé¡¹ç›®"><a href="#ä½“éªŒé¡¹ç›®" class="headerlink" title="ä½“éªŒé¡¹ç›®"></a>ä½“éªŒé¡¹ç›®</h1><blockquote>
<ul>
<li><p><em><strong>æ»‘é›ª</strong></em>ï¼šx</p>
</li>
<li><p><em><strong>æ»‘å†°</strong></em>ï¼šxx</p>
</li>
</ul>
</blockquote>
<hr>
<h1 id="æ¸¸ç©è¡Œç¨‹"><a href="#æ¸¸ç©è¡Œç¨‹" class="headerlink" title="æ¸¸ç©è¡Œç¨‹"></a>æ¸¸ç©è¡Œç¨‹</h1><h2 id="1-å“ˆå°”æ»¨"><a href="#1-å“ˆå°”æ»¨" class="headerlink" title="1. å“ˆå°”æ»¨"></a>1. å“ˆå°”æ»¨</h2><p>xx</p>
]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
        <category>travel.china</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>å›½å†…æ¸¸.äº”å²³</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%86%85%E6%B8%B8.%E4%BA%94%E5%B2%B3/</url>
    <content><![CDATA[<h1 id="é‡ç‚¹ä¿¡æ¯"><a href="#é‡ç‚¹ä¿¡æ¯" class="headerlink" title="é‡ç‚¹ä¿¡æ¯"></a>é‡ç‚¹ä¿¡æ¯</h1><h2 id="äº‹å‰å‡†å¤‡"><a href="#äº‹å‰å‡†å¤‡" class="headerlink" title="äº‹å‰å‡†å¤‡"></a>äº‹å‰å‡†å¤‡</h2><table>
    <!--  -->
    <tr style="background-color: #f7f7f7;">
        <td align='center'>åœ°å›¾</td>
        <td align='center'>è£…å¤‡</td>
    </tr>
    <tr> <td rowspan="9"><img align='center' src="/image/travel/china/wuyue/locations.jpg" width="90%"></td> </tr>
    <tr> <td> 1. <strong>å¿…å¸¦:</strong> ç§»åŠ¨ç”µæºã€èº«ä»½è¯ã€å­¦ç”Ÿè¯ </td> </tr>
    <tr> <td> 2. <strong>è¡£ç‰©:</strong> ç™»å±±é‹ã€å†²é”‹è¡£ã€é€Ÿå¹²è¡£è£¤ã€æ‰‹å¥—ã€å¸½å­ã€å¢¨é•œã€æŠ¤è† </td> </tr>
    <tr> <td> 3. <strong>é¥®æ–™:</strong> çŸ¿æ³‰æ°´(å¤§)(æˆ–æ™¯åŒºè´­ä¹°)ã€ç”µè§£è´¨é¥®æ–™ </td> </tr>
    <tr> <td> 4. <strong>é£Ÿç‰©:</strong> å·§å…‹åŠ›ã€ç‰›è‚‰å¹²ã€èƒ½é‡æ£’ã€åšæœã€æ°´æœ </td> </tr>
    <tr> <td> 5. <strong>å·¥å…·:</strong> ç™»å±±åŒ…(èƒŒè´Ÿç³»ç»Ÿ)ã€ç™»å±±æ–ã€è¿åŠ¨æ‰‹è¡¨ã€ä¿æ¸©æ¯ã€æ‹ç«‹å¾— </td> </tr>
    <tr> <td> 6. <strong>è¯ç‰©:</strong> æ€¥æ•‘åŒ…ã€åˆ›å£è´´ã€è—¿é¦™æ­£æ°”æ°´ã€ </td> </tr>
    <tr> <td> 7. <strong>ç”¨å“:</strong> çº¸å·¾ã€å£é¦™ç³–ã€ä¸€æ¬¡æ€§æ¯›å·¾ã€ä¸€æ¬¡æ€§é›¨è¡£ </td> </tr>
    <tr> <td> <strong>å¤‡æ³¨:</strong> å—å²³è¡¡å±±ä½œä¸ºæœ€åä¸€ç«™, ç›´æ¥é¢†å–äº”å²³å¥–ç‰Œ </td> </tr>
</table>

<h2 id="é—¨ç¥¨ä»·æ ¼"><a href="#é—¨ç¥¨ä»·æ ¼" class="headerlink" title="é—¨ç¥¨ä»·æ ¼"></a>é—¨ç¥¨ä»·æ ¼</h2><table>
<thead>
<tr>
<th>ä¸‰å±±äº”å²³</th>
<th>æµ·æ‹”</th>
<th>å¼€æ”¾æ—¶é—´</th>
<th>é—¨ç¥¨ä»·æ ¼</th>
<th>ç´¢é“æ—¶é—´</th>
<th>ç´¢é“ä»·æ ¼</th>
</tr>
</thead>
<tbody><tr>
<td>åŒ—å²³æ’å±±</td>
<td>2016.1m</td>
<td>8:00-17:30</td>
<td>ï¿¥45</td>
<td>8:00-16:30</td>
<td>ï¿¥70</td>
</tr>
<tr>
<td>ä¸œå²³æ³°å±±</td>
<td>1545m</td>
<td>5:00-24:00</td>
<td>ï¿¥115</td>
<td>ä¸­å¤©é—¨-å—å¤©é—¨: 7:30-17:00 <br> æ¡ƒèŠ±æº-å—å¤©é—¨: 8:00-16:30</td>
<td>ï¿¥100</td>
</tr>
<tr>
<td>ä¸­å²³åµ©å±±</td>
<td>1491.7m</td>
<td>8:00-17:00</td>
<td>ï¿¥30</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>è¥¿å²³åå±±</td>
<td>2154.9m</td>
<td>0:00-24:00</td>
<td>ï¿¥160</td>
<td>åŒ—å³°ç´¢é“: 6:40-19:00 <br> è¥¿å³°ç´¢é“: 7:00-19:00</td>
<td>è¥¿å³°: ï¿¥140 <br> åŒ—å³°: ï¿¥80</td>
</tr>
<tr>
<td>å—å²³è¡¡å±±</td>
<td>1300.2m</td>
<td>7:30-17:30</td>
<td>ï¿¥80</td>
<td>å—å¤©é—¨-åŠå±±äº­: 7:00-17:30</td>
<td>ï¿¥44</td>
</tr>
</tbody></table>
<h2 id="è®¡åˆ’å®‰æ’"><a href="#è®¡åˆ’å®‰æ’" class="headerlink" title="è®¡åˆ’å®‰æ’"></a>è®¡åˆ’å®‰æ’</h2><h3 id="å—å²³è¡¡å±±-æœ€åä¸€ç«™-ç›´æ¥é¢†å¥–ç‰Œ"><a href="#å—å²³è¡¡å±±-æœ€åä¸€ç«™-ç›´æ¥é¢†å¥–ç‰Œ" class="headerlink" title="å—å²³è¡¡å±± (æœ€åä¸€ç«™, ç›´æ¥é¢†å¥–ç‰Œ)"></a>å—å²³è¡¡å±± (æœ€åä¸€ç«™, ç›´æ¥é¢†å¥–ç‰Œ)</h3><table>
<thead>
<tr>
<th>æ—¶é—´</th>
<th>è®¡åˆ’</th>
<th>ç±»å‹</th>
<th>é¢„ç®—</th>
<th>å¤‡æ³¨</th>
</tr>
</thead>
<tbody><tr>
<td>8:00-8:30</td>
<td>å—å²³å¤§å·´ï¼šè¡¡å±±ç«™-&gt;è¡¡å±±é£æ™¯åŒº</td>
<td>äº¤é€š</td>
<td>8.00</td>
<td></td>
</tr>
<tr>
<td>å•å…ƒæ ¼</td>
<td>å•å…ƒæ ¼</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>è¡¡å±±æ”»ç•¥â€¦â€¦</p>
<h3 id="ä¸­å²³åµ©å±±"><a href="#ä¸­å²³åµ©å±±" class="headerlink" title="ä¸­å²³åµ©å±±"></a>ä¸­å²³åµ©å±±</h3><p>åµ©å±±æ”»ç•¥â€¦â€¦</p>
<h3 id="ä¸œå²³æ³°å±±"><a href="#ä¸œå²³æ³°å±±" class="headerlink" title="ä¸œå²³æ³°å±±"></a>ä¸œå²³æ³°å±±</h3><p>æ—¥å‡ºä¸œæ–¹ï¼Œå¤œçˆ¬æ³°å±±çœ‹æ—¥å‡º</p>
<h3 id="åŒ—å²³æ’å±±"><a href="#åŒ—å²³æ’å±±" class="headerlink" title="åŒ—å²³æ’å±±"></a>åŒ—å²³æ’å±±</h3><p>æ’å±±æ”»ç•¥â€¦â€¦</p>
<h3 id="è¥¿å²³åå±±"><a href="#è¥¿å²³åå±±" class="headerlink" title="è¥¿å²³åå±±"></a>è¥¿å²³åå±±</h3><p>åå±±æ”»ç•¥â€¦â€¦</p>
]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>å›½å†…æ¸¸.è¥¿å®‰</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%86%85%E6%B8%B8.%E8%A5%BF%E5%AE%89/</url>
    <content><![CDATA[<h1 id="å¤§å”ä¸å¤œåŸ"><a href="#å¤§å”ä¸å¤œåŸ" class="headerlink" title="å¤§å”ä¸å¤œåŸ"></a>å¤§å”ä¸å¤œåŸ</h1><p>xxx</p>
]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>å›½å†…æ¸¸.è¥¿è—</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%86%85%E6%B8%B8.%E8%A5%BF%E8%97%8F/</url>
    <content><![CDATA[<h1 id="ä½“éªŒé¡¹ç›®"><a href="#ä½“éªŒé¡¹ç›®" class="headerlink" title="ä½“éªŒé¡¹ç›®"></a>ä½“éªŒé¡¹ç›®</h1><blockquote>
<ul>
<li>è‡ªé©¾5000å…¬é‡Œ</li>
</ul>
</blockquote>
<h1 id="æ¸¸ç©è¡Œç¨‹"><a href="#æ¸¸ç©è¡Œç¨‹" class="headerlink" title="æ¸¸ç©è¡Œç¨‹"></a>æ¸¸ç©è¡Œç¨‹</h1><h2 id="å¦é—¨å‡ºå‘"><a href="#å¦é—¨å‡ºå‘" class="headerlink" title="å¦é—¨å‡ºå‘"></a>å¦é—¨å‡ºå‘</h2><h2 id="æˆéƒ½å‡ºå‘"><a href="#æˆéƒ½å‡ºå‘" class="headerlink" title="æˆéƒ½å‡ºå‘"></a>æˆéƒ½å‡ºå‘</h2><h3 id="æ³¨æ„äº‹é¡¹"><a href="#æ³¨æ„äº‹é¡¹" class="headerlink" title="æ³¨æ„äº‹é¡¹"></a>æ³¨æ„äº‹é¡¹</h3><ul>
<li>é¢„é˜²é«˜å</li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
        <category>travel.china</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>Large Language Models</title>
    <url>/2024/05/01/study/llm/llm/</url>
    <content><![CDATA[<h2 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h2><h3 id="source-https-github-com-RUCAIBox-Top-conference-paper-list-blob-main-EMNLP2022-ICLR2023-LLM-papers-md"><a href="#source-https-github-com-RUCAIBox-Top-conference-paper-list-blob-main-EMNLP2022-ICLR2023-LLM-papers-md" class="headerlink" title="source: https://github.com/RUCAIBox/Top-conference-paper-list/blob/main/EMNLP2022_ICLR2023_LLM_papers.md"></a>source: <a href="https://github.com/RUCAIBox/Top-conference-paper-list/blob/main/EMNLP2022_ICLR2023_LLM_papers.md">https://github.com/RUCAIBox/Top-conference-paper-list/blob/main/EMNLP2022_ICLR2023_LLM_papers.md</a></h3><h1 id="Catalog-ç›®å½•"><a href="#Catalog-ç›®å½•" class="headerlink" title="Catalog(ç›®å½•)"></a>Catalog(ç›®å½•)</h1><ul>
<li><a href="#catalog%E7%9B%AE%E5%BD%95">Catalog(ç›®å½•)</a><ul>
<li><a href="#training%E8%AE%AD%E7%BB%83">Trainingã€è®­ç»ƒã€‘</a><ul>
<li><a href="#pre-training%E9%A2%84%E8%AE%AD%E7%BB%83">Pre-Trainingã€é¢„è®­ç»ƒã€‘</a></li>
<li><a href="#instruction-tuning%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83">Instruction Tuningã€æŒ‡ä»¤å¾®è°ƒã€‘</a></li>
</ul>
</li>
<li><a href="#utilization%E4%BD%BF%E7%94%A8">Utilizationã€ä½¿ç”¨ã€‘</a><ul>
<li><a href="#in-context-learning%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0">In-Context Learningã€ä¸Šä¸‹æ–‡å­¦ä¹ ã€‘</a></li>
<li><a href="#chain-of-thought-prompting%E6%80%9D%E7%BB%B4%E9%93%BE%E6%8F%90%E7%A4%BA">Chain-of-Thought Promptingã€æ€ç»´é“¾æç¤ºã€‘</a></li>
<li><a href="#z%E5%8E%8B%E7%BC%A9">zã€å‹ç¼©ã€‘</a></li>
<li><a href="#others%E5%85%B6%E4%BB%96">Othersã€å…¶ä»–ã€‘</a></li>
</ul>
</li>
<li><a href="#application%E5%BA%94%E7%94%A8">Applicationã€åº”ç”¨ã€‘</a><ul>
<li><a href="#multi-modal%E5%A4%9A%E6%A8%A1%E6%80%81">Multi-Modalã€å¤šæ¨¡æ€ã€‘</a></li>
<li><a href="#code%E4%BB%A3%E7%A0%81">Codeã€ä»£ç ã€‘</a></li>
<li><a href="#retrieval%E6%A3%80%E7%B4%A2">Retrievalã€æ£€ç´¢ã€‘</a></li>
<li><a href="#text-generation%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90">Text Generationã€æ–‡æœ¬ç”Ÿæˆã€‘</a></li>
<li><a href="#others%E5%85%B6%E4%BB%96-1">Othersã€å…¶ä»–ã€‘</a></li>
</ul>
</li>
<li><a href="#analysis--evaluation%E5%88%86%E6%9E%90%E4%B8%8E%E8%AF%84%E6%B5%8B">Analysis &amp; Evaluationã€åˆ†æä¸è¯„æµ‹ã€‘</a></li>
</ul>
</li>
</ul>
<h2 id="Trainingã€è®­ç»ƒã€‘"><a href="#Trainingã€è®­ç»ƒã€‘" class="headerlink" title="Trainingã€è®­ç»ƒã€‘"></a>Trainingã€è®­ç»ƒã€‘</h2><h3 id="Pre-Trainingã€é¢„è®­ç»ƒã€‘"><a href="#Pre-Trainingã€é¢„è®­ç»ƒã€‘" class="headerlink" title="Pre-Trainingã€é¢„è®­ç»ƒã€‘"></a>Pre-Trainingã€é¢„è®­ç»ƒã€‘</h3><ul>
<li>UL2: Unifying Language Learning Paradigms</li>
<li>Learning to Grow Pretrained Models for Efficient Transformer Training</li>
<li>Efficient Large Scale Language Modeling with Mixtures of Experts</li>
<li>Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models</li>
<li>CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis</li>
<li>InCoder: A Generative Model for Code Infilling and Synthesis</li>
<li>CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code</li>
<li>CodeRetriever: A Large Scale Contrastive Pre-Training Method for Code Search</li>
<li>UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining</li>
<li>GLM-130B: An Open Bilingual Pre-trained Model</li>
<li>When FLUE Meets FLANG: Benchmarks and Large Pretrained Language Model for Financial Domain</li>
</ul>
<h3 id="Instruction-Tuningã€æŒ‡ä»¤å¾®è°ƒã€‘"><a href="#Instruction-Tuningã€æŒ‡ä»¤å¾®è°ƒã€‘" class="headerlink" title="Instruction Tuningã€æŒ‡ä»¤å¾®è°ƒã€‘"></a>Instruction Tuningã€æŒ‡ä»¤å¾®è°ƒã€‘</h3><ul>
<li>What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment</li>
<li>InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning</li>
<li>Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization</li>
<li>Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks</li>
<li>Boosting Natural Language Generation from Instructions with Meta-Learning</li>
<li>Help me write a Poem - Instruction Tuning as a Vehicle for Collaborative Poetry Writing</li>
<li>Multitask Instruction-based Prompting for Fallacy Recognition</li>
<li>Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization</li>
<li>HypeR: Multitask Hyper-Prompted Training Enables Large-Scale Retrieval Generalization</li>
</ul>
<h2 id="Utilizationã€ä½¿ç”¨ã€‘"><a href="#Utilizationã€ä½¿ç”¨ã€‘" class="headerlink" title="Utilizationã€ä½¿ç”¨ã€‘"></a>Utilizationã€ä½¿ç”¨ã€‘</h2><h3 id="In-Context-Learningã€ä¸Šä¸‹æ–‡å­¦ä¹ ã€‘"><a href="#In-Context-Learningã€ä¸Šä¸‹æ–‡å­¦ä¹ ã€‘" class="headerlink" title="In-Context Learningã€ä¸Šä¸‹æ–‡å­¦ä¹ ã€‘"></a>In-Context Learningã€ä¸Šä¸‹æ–‡å­¦ä¹ ã€‘</h3><ul>
<li>â€‹â€‹What learning algorithm is in-context learning? Investigations with linear models</li>
<li>Ask Me Anything: A simple strategy for prompting language models</li>
<li>Large Language Models are Human-Level Prompt Engineers</li>
<li>Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks</li>
<li>kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference</li>
<li>Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners</li>
<li>Selective Annotation Makes Language Models Better Few-Shot Learners</li>
<li>Active Example Selection for In-Context Learning</li>
<li>Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?</li>
<li>In-Context Learning for Few-Shot Dialogue State Tracking</li>
<li>Few-Shot Anaphora Resolution in Scientific Protocols via Mixtures of In-Context Experts</li>
<li>ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback</li>
<li>Controllable Dialogue Simulation with In-context Learning</li>
<li>Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again</li>
<li>XRICL: Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing</li>
<li>On the Compositional Generalization Gap of In-Context Learning</li>
<li>Towards In-Context Non-Expert Evaluation of Reflection Generation for Counselling Conversations</li>
<li>Towards Few-Shot Identification of Morality Frames using In-Context Learning</li>
</ul>
<h3 id="Chain-of-Thought-Promptingã€æ€ç»´é“¾æç¤ºã€‘"><a href="#Chain-of-Thought-Promptingã€æ€ç»´é“¾æç¤ºã€‘" class="headerlink" title="Chain-of-Thought Promptingã€æ€ç»´é“¾æç¤ºã€‘"></a>Chain-of-Thought Promptingã€æ€ç»´é“¾æç¤ºã€‘</h3><ul>
<li>ReAct: Synergizing Reasoning and Acting in Language Models</li>
<li>Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning</li>
<li>Neuro-Symbolic Procedural Planning with Commonsense Prompting</li>
<li>Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought</li>
<li>PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales</li>
<li>Decomposed Prompting: A Modular Approach for Solving Complex Tasks</li>
<li>Complexity-Based Prompting for Multi-step Reasoning</li>
<li>Automatic Chain of Thought Prompting in Large Language Models</li>
<li>Compositional Semantic Parsing with Large Language Models</li>
<li>Self-Consistency Improves Chain of Thought Reasoning in Language Models</li>
<li>Least-to-Most Prompting Enables Complex Reasoning in Large Language Models</li>
<li>Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning</li>
<li>Iteratively Prompt Pre-trained Language Models for Chain of Thought</li>
<li>ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering</li>
<li>Induced Natural Language Rationales and Interleaved Markup Tokens Enable Extrapolation in Large Language Models</li>
</ul>
<h3 id="zã€å‹ç¼©ã€‘"><a href="#zã€å‹ç¼©ã€‘" class="headerlink" title="zã€å‹ç¼©ã€‘"></a>zã€å‹ç¼©ã€‘</h3><ul>
<li>Understanding and Improving Knowledge Distillation for Quantization Aware Training of Large Transformer Encoders</li>
<li>The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models</li>
<li>AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of Large-Scale Pre-Trained Language Models</li>
</ul>
<h3 id="Othersã€å…¶ä»–ã€‘"><a href="#Othersã€å…¶ä»–ã€‘" class="headerlink" title="Othersã€å…¶ä»–ã€‘"></a>Othersã€å…¶ä»–ã€‘</h3><ul>
<li>BBTv2: Towards a Gradient-Free Future with Large Language Models</li>
<li>Compositional Task Representations for Large Language Models</li>
<li>Just Fine-tune Twice: Selective Differential Privacy for Large Language Models</li>
</ul>
<h2 id="Applicationã€åº”ç”¨ã€‘"><a href="#Applicationã€åº”ç”¨ã€‘" class="headerlink" title="Applicationã€åº”ç”¨ã€‘"></a>Applicationã€åº”ç”¨ã€‘</h2><h3 id="Multi-Modalã€å¤šæ¨¡æ€ã€‘"><a href="#Multi-Modalã€å¤šæ¨¡æ€ã€‘" class="headerlink" title="Multi-Modalã€å¤šæ¨¡æ€ã€‘"></a>Multi-Modalã€å¤šæ¨¡æ€ã€‘</h3><ul>
<li>Visual Classification via Description from Large Language Models</li>
<li>Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language</li>
<li>Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training</li>
</ul>
<h3 id="Codeã€ä»£ç ã€‘"><a href="#Codeã€ä»£ç ã€‘" class="headerlink" title="Codeã€ä»£ç ã€‘"></a>Codeã€ä»£ç ã€‘</h3><ul>
<li>DocPrompting: Generating Code by Retrieving the Docs</li>
<li>Planning with Large Language Models for Code Generation</li>
<li>CodeT: Code Generation with Generated Tests</li>
<li>Language Models Can Teach Themselves to Program Better</li>
</ul>
<h3 id="Retrievalã€æ£€ç´¢ã€‘"><a href="#Retrievalã€æ£€ç´¢ã€‘" class="headerlink" title="Retrievalã€æ£€ç´¢ã€‘"></a>Retrievalã€æ£€ç´¢ã€‘</h3><ul>
<li>Promptagator: Few-shot Dense Retrieval From 8 Examples</li>
<li>Recitation-Augmented Language Models</li>
<li>Generate rather than Retrieve: Large Language Models are Strong Context Generators</li>
<li>QUILL: Query Intent with Large Language Models using Retrieval Augmentation and Multi-stage Distillation</li>
</ul>
<h3 id="Text-Generationã€æ–‡æœ¬ç”Ÿæˆã€‘"><a href="#Text-Generationã€æ–‡æœ¬ç”Ÿæˆã€‘" class="headerlink" title="Text Generationã€æ–‡æœ¬ç”Ÿæˆã€‘"></a>Text Generationã€æ–‡æœ¬ç”Ÿæˆã€‘</h3><ul>
<li>Generating Sequences by Learning to Self-Correct</li>
<li>RankGen: Improving Text Generation with Large Ranking Models</li>
<li>Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation</li>
</ul>
<h3 id="Othersã€å…¶ä»–ã€‘-1"><a href="#Othersã€å…¶ä»–ã€‘-1" class="headerlink" title="Othersã€å…¶ä»–ã€‘"></a>Othersã€å…¶ä»–ã€‘</h3><ul>
<li>Systematic Rectification of Language Models via Dead-end Analysis</li>
<li>Reward Design with Language Models</li>
<li>Bidirectional Language Models Are Also Few-shot Learners</li>
<li>Composing Ensembles of Pre-trained Models via Iterative Consensus</li>
<li>Binding Language Models in Symbolic Languages</li>
<li>Mindâ€™s Eye: Grounded Language Model Reasoning through Simulation</li>
</ul>
<h2 id="Analysis-Evaluationã€åˆ†æä¸è¯„æµ‹ã€‘"><a href="#Analysis-Evaluationã€åˆ†æä¸è¯„æµ‹ã€‘" class="headerlink" title="Analysis &amp; Evaluationã€åˆ†æä¸è¯„æµ‹ã€‘"></a>Analysis &amp; Evaluationã€åˆ†æä¸è¯„æµ‹ã€‘</h2><ul>
<li>WikiWhy: Answering and Explaining Cause-and-Effect Questions</li>
<li>ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning</li>
<li>Quantifying Memorization Across Neural Language Models</li>
<li>Mass-Editing Memory in a Transformer</li>
<li>Multi-lingual Evaluation of Code Generation Models</li>
<li>STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK</li>
<li>Leveraging Large Language Models for Multiple Choice Question Answering</li>
<li>Broken Neural Scaling Laws</li>
<li>Language models are multilingual chain-of-thought reasoners</li>
<li>Language Models are Realistic Tabular Data Generators</li>
<li>Task Ambiguity in Humans and Language Models</li>
<li>Discovering Latent Knowledge in Language Models Without Supervision</li>
<li>Prompting GPT-3 To Be Reliable</li>
<li>Large language models are few-shot clinical information extractors</li>
<li>How Large Language Models are Transforming Machine-Paraphrase Plagiarism</li>
<li>Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs</li>
<li>SLING: Sino Linguistic Evaluation of Large Language Models</li>
<li>A Systematic Investigation of Commonsense Knowledge in Large Language Models</li>
<li>Lexical Generalization Improves with Larger Models and Longer Training</li>
<li>What do Large Language Models Learn beyond Language?</li>
<li>Probing for Understanding of English Verb Classes and Alternations in Large Pre-trained Language Models</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
        <category>llm</category>
      </categories>
      <tags>
        <tag>study.llm</tag>
      </tags>
  </entry>
  <entry>
    <title>å›½å¤–æ¸¸.æ–°åŠ å¡</title>
    <url>/2024/05/02/wish/travel/%E5%9B%BD%E5%A4%96%E6%B8%B8.%E6%96%B0%E5%8A%A0%E5%9D%A1/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>wish</category>
        <category>travel</category>
      </categories>
      <tags>
        <tag>wish.travel</tag>
      </tags>
  </entry>
  <entry>
    <title>Modality Large Language Model</title>
    <url>/2024/05/01/study/llm/mllm/</url>
    <content><![CDATA[<h2 id="1-è¯­è¨€æ¨¡å‹å‘å±•é˜¶æ®µ"><a href="#1-è¯­è¨€æ¨¡å‹å‘å±•é˜¶æ®µ" class="headerlink" title="1. è¯­è¨€æ¨¡å‹å‘å±•é˜¶æ®µ"></a>1. è¯­è¨€æ¨¡å‹å‘å±•é˜¶æ®µ</h2><p>This is MLLM Technique</p>
]]></content>
      <categories>
        <category>study</category>
        <category>llm</category>
      </categories>
      <tags>
        <tag>study.llm</tag>
      </tags>
  </entry>
  <entry>
    <title>Prompt-Tuning</title>
    <url>/2024/05/01/study/llm/prompt/</url>
    <content><![CDATA[<h2 id="1-è¯­è¨€æ¨¡å‹å‘å±•é˜¶æ®µ"><a href="#1-è¯­è¨€æ¨¡å‹å‘å±•é˜¶æ®µ" class="headerlink" title="1. è¯­è¨€æ¨¡å‹å‘å±•é˜¶æ®µ"></a>1. è¯­è¨€æ¨¡å‹å‘å±•é˜¶æ®µ</h2><ul>
<li><p><strong>ç¬¬ä¸€é˜¶æ®µ</strong>: Task-specific Fine-tuning</p>
<p>  <em><strong>è¿‡ç¨‹</strong></em>ï¼šå¯¹äºå…·ä½“ä»»åŠ¡ï¼Œä»¥é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸ºbackboneï¼Œå¼•å…¥é¢å¤–å‚æ•°é€‚é…ä»»åŠ¡ï¼Œè¿›è¡Œfine-tuningã€‚</p>
<p>  <em><strong>é—®é¢˜</strong></em>ï¼šâ‘  ä¸‹æ¸¸ä»»åŠ¡ç›®æ ‡ä¸é¢„è®­ç»ƒç›®æ ‡å·®è·è¿‡å¤§ï¼›â‘¡ å¾®è°ƒä¾èµ–å¤§é‡ç›‘ç£è¯­æ–™</p>
<p>  <em><strong>ä»£è¡¨</strong></em>ï¼šBERTã€GPTã€XLNet</p>
</li>
<li><p><strong>ç¬¬äºŒé˜¶æ®µ</strong>: Prompt-tuning</p>
<p>  <em><strong>è¿‡ç¨‹</strong></em>ï¼šé€æ­¥æ‰©â¼¤æ¨¡å‹å‚æ•°å’Œè®­ç»ƒè¯­æ–™è§„æ¨¡ï¼Œæ¢ç´¢ä¸åŒç±»å‹çš„æ¶æ„ã€‚</p>
<p>  <em><strong>ä»£è¡¨</strong></em>ï¼šBARTã€T5ã€GPT-3ç­‰ï¼›</p>
</li>
<li><p><strong>ç¬¬ä¸‰é˜¶æ®µ</strong>: </p>
<p>  <em><strong>è¿‡ç¨‹</strong></em>ï¼šâ¾›å‘AIGCï¼ˆArtificial Intelligent Generated Contentï¼‰æ—¶ä»£ï¼Œæ¨¡å‹å‚æ•°è§„æ¨¡æ­¥â¼Šåƒä¸‡äº¿ï¼Œæ¨¡å‹æ¶æ„ä¸ºâ¾ƒå›å½’æ¶æ„ï¼Œâ¼¤æ¨¡å‹â¾›å‘å¯¹è¯å¼ã€â½£æˆå¼ã€å¤šæ¨¡æ€æ—¶ä»£ï¼Œæ›´åŠ æ³¨é‡ä¸â¼ˆç±»äº¤äº’è¿›â¾å¯¹â»¬ï¼Œå®ç°å¯é ã€å®‰å…¨ã€â½†æ¯’çš„æ¨¡å‹ã€‚</p>
<p>  <em><strong>ä»£è¡¨</strong></em>ï¼šInstructionGPTã€Cha tGPTã€Bardã€GPT-4ç­‰ã€‚</p>
</li>
</ul>
<div align=center><img src="https://cdn.jsdelivr.net/gh/jianzquan/Rep4MyPage/img/LLM.jpg" width="800"></div>
<br/>


<h2 id="2-Prompt-Tuning"><a href="#2-Prompt-Tuning" class="headerlink" title="2. Prompt-Tuning"></a>2. Prompt-Tuning</h2><p>prompt-tuning èµ·æºäºGPT-3ï¼ŒGPT-3å¼€åˆ›æ€§åœ°æå‡ºäº†in-context learning&#x2F;demonstrate learningï¼Œç”±äºå…¶æ˜¯å»ºç«‹åœ¨å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸Šçš„ï¼Œå‚æ•°é‡å¤§äº10Bï¼Œåœ¨çœŸå®åœºæ™¯ä¸­å¾ˆéš¾åº”ç”¨ã€‚è¿™å¥—æ–¹æ³•åº”ç”¨åœ¨å°æ¨¡å‹ä¸Šï¼Œå°±æ˜¯prompt-tuningäº†ã€‚</p>
<p>prompt-tuning æ—¨åœ¨è§£å†³ä¼ ç»Ÿfine-tuningçš„ä¸¤ä¸ªç—›ç‚¹é—®é¢˜ï¼š</p>
<ul>
<li><em><strong>é™ä½è¯­ä¹‰å·®å¼‚</strong></em>ï¼šç¼©å°pre-trainingä¸fine-tuningä¸¤ä¸ªé˜¶æ®µç›®æ ‡å·®è·ã€‚</li>
<li><em><strong>é¿å…è¿‡æ‹Ÿåˆ</strong></em>ï¼šé€šè¿‡æ·»åŠ æ¨¡æ¿çš„æ–¹å¼é¿å…å¼•å…¥é¢å¤–çš„å‚æ•°ï¼Œè¿›è€Œé€ æˆçš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚<br/></li>
</ul>
<p>Prompt-tuning ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼šï¼ˆè¿˜æœ‰Ensemblingçš„ç©æ³•ï¼‰</p>
<ul>
<li><p>æ¨¡æ¿æ„å»º(template): (å¤§é‡ä¼˜åŒ–æ–¹æ³•)</p>
<p>äººå·¥æ„å»º</p>
<p>å¯å‘å¼å‘ï¼šPTRã€AutoPrompt</p>
<p>ç”Ÿæˆï¼šLM-BFFã€</p>
<p>è¯å‘é‡å¾®è°ƒ</p>
<p>ä¼ªæ ‡è®°ï¼šPrompt Tuningã€P-tuningã€Pre-trained Prompt Tuningã€</p>
</li>
<li><p>æ ‡ç­¾è¯æ˜ å°„(label word verbilizer): KPTã€ProtoVerbã€</p>
</li>
</ul>
<div align=center><img src="https://cdn.jsdelivr.net/gh/jianzquan/Rep4MyPage/img/Prompt.jpg" width="800"></div>

<br/>

<h2 id="3-é¢å‘LLMçš„Prompt-Tuning"><a href="#3-é¢å‘LLMçš„Prompt-Tuning" class="headerlink" title="3. é¢å‘LLMçš„Prompt-Tuning"></a>3. é¢å‘LLMçš„Prompt-Tuning</h2><p>ç ”ç©¶å‘ç°ï¼Œå¯¹äºè¶…è¿‡10äº¿å‚æ•°é‡çš„æ¨¡å‹æ¥è¯´ã€‚Prompt-tuningæ‰€å¸¦æ¥çš„æ”¶ç›Šè¿œè¿œé«˜äºæ ‡å‡†çš„Fine-tuningã€‚</p>
<p>å‚æ•°é‡å¤Ÿå¤§ã€è¯­æ–™è¶³å¤Ÿå¤šã€é¢„è®­ç»ƒä»»åŠ¡è¶³å¤Ÿæœ‰æ•ˆï¼Œå°±èƒ½å¾ˆå¥½çš„å®ç°å…å‚æ•°è®­ç»ƒçš„é›¶æ ·æœ¬å­¦ä¹ ã€‚</p>
<p>LLMçš„Prompt-tuningæ–¹æ³•ï¼š</p>
<ul>
<li><p><strong>In-Context Learning</strong>: (ç ”ç©¶è®ºæ–‡&#x2F;æŠ€æœ¯å¾ˆå¤šå¾ˆå¤š)</p>
<p>  <em><strong>è¿‡ç¨‹</strong></em>ï¼šä»è®­ç»ƒé›†ä¸­æŒ‘é€‰å°‘é‡çš„æ ‡æ³¨æ ·æœ¬ï¼Œè®¾è®¡ä»»åŠ¡ç›¸å…³çš„æŒ‡ä»¤å½¢æˆæç¤ºæ¨¡æ¿ï¼Œç”¨äºæŒ‡å¯¼æµ‹è¯•æ ·æœ¬ç”Ÿæˆç›¸åº”çš„ç»“æœã€‚</p>
  <div align=center><img src="https://cdn.jsdelivr.net/gh/jianzquan/Rep4MyPage/img/ICT.jpg" width="700"></div>
  
<p>  <em><strong>é—®é¢˜</strong></em>ï¼šå¦‚ä½•é€‰æ‹©æ ·æœ¬ï¼Ÿå¦‚ä½•ç»„åˆæ ·æœ¬ï¼Ÿ(æ–¹å·®å¤§ã€ä¸ç¨³å®šé—®é¢˜)</p>
</li>
<li><p><strong>Instruction-tuning</strong>:</p>
<p>  <em><strong>è¿‡ç¨‹</strong></em>ï¼šä¸ºå„ç§ä»»åŠ¡å®šä¹‰æŒ‡ä»¤ï¼ŒæŒ‰æŒ‡ä»¤æ¨¡æ¿é‡æ„è¾“å…¥è¿›è¡Œè®­ç»ƒã€‚</p>
</li>
<li><p><strong>Chain-of-Thought</strong>: è¿›ä¸€æ­¥æé«˜è¶…å¤§æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„æ¨ç†èƒ½åŠ›ã€‚</p>
<p>  <em><strong>è¿‡ç¨‹</strong></em>ï¼šä»£ç çš„é¢„è®­ç»ƒ</p>
</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
        <category>llm</category>
      </categories>
      <tags>
        <tag>study.llm</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM.Tuning</title>
    <url>/2024/05/25/study/llm/adapter/</url>
    <content><![CDATA[<div align=center><img src="/image/study/llm/peft.jpg" width="800"></div> <br>

<p>Thanks to: <a href="https://zhuanlan.zhihu.com/p/675231376">https://zhuanlan.zhihu.com/p/675231376</a><br>Library: <a href="https://github.com/adapter-hub/adapters">https://github.com/adapter-hub/adapters</a></p>
<h2 id="Fine-Tuning"><a href="#Fine-Tuning" class="headerlink" title="Fine-Tuning"></a>Fine-Tuning</h2><ul>
<li>è°ƒæ•´ PLM&#x2F;LLM æ‰€æœ‰å±‚å’Œå‚æ•°, ä½¿å…¶é€‚åº”ç‰¹å®šä»»åŠ¡.</li>
<li>ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ &amp; ç‰¹å®šä»»åŠ¡çš„æ•°æ®è¿›è¡Œ.</li>
<li>ä¼˜ç‚¹: å……åˆ†åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„é€šç”¨ç‰¹å¾; ç¼ºç‚¹: éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æº.</li>
</ul>
<h2 id="Parameter-Efficient-Fine-Tuning"><a href="#Parameter-Efficient-Fine-Tuning" class="headerlink" title="Parameter Efficient Fine-Tuning"></a>Parameter Efficient Fine-Tuning</h2><ul>
<li>æœ€å°åŒ–å¾®è°ƒå‚æ•°çš„æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦, æå¤§é™ä½è®­ç»ƒæˆæœ¬.</li>
<li>ä¸æ”¹å˜ PLM&#x2F;LLM çŸ¥è¯†å‰æä¸‹, è¿…é€Ÿé€‚åº”æ–°ä»»åŠ¡ï¼Œå®ç°é«˜æ•ˆçš„è¿ç§»å­¦ä¹ .</li>
<li>æé«˜æ¨¡å‹æ•ˆæœçš„åŒæ—¶, å¤§å¤§ç¼©çŸ­æ¨¡å‹è®­ç»ƒæ—¶é—´å’Œè®¡ç®—æˆæœ¬</li>
</ul>
<table>
    <tr style="background-color: #f7f7f7;">
        <td align='center'>Methods</td>
        <td align='center'>Principle</td>
    </tr>
    <tr> 
        <td> 
            <strong> 1. [LoRA](https://arxiv.org/abs/2106.09685): </strong> 
            <br> 1. å¥½ï¼Œå¾ˆå¥½ï¼Œéå¸¸å¥½ 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
    <tr> 
        <td> 
            <strong> 2. QLoRA: </strong> 
            <br> 1. å¥½ï¼Œå¾ˆå¥½ï¼Œéå¸¸å¥½ 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
    <tr> 
        <td> 
            <strong> 3. Adapter Tuning: </strong> 
            <br> 1. å¥½ï¼Œå¾ˆå¥½ï¼Œéå¸¸å¥½ 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
    <tr> 
        <td> 
            <strong> 4. Prefix Tuning: </strong> 
            <br> 1. å¥½ï¼Œå¾ˆå¥½ï¼Œéå¸¸å¥½ 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
    <tr> 
        <td> 
            <strong> 5. Prompt Tuning: </strong> 
            <br> * å¥½ï¼Œå¾ˆå¥½ï¼Œéå¸¸å¥½ 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
    <tr> 
        <td> 
            <strong> 6. P Tuning & v2: </strong> 
            <br> 1. å¥½ï¼Œå¾ˆå¥½ï¼Œéå¸¸å¥½ 
        </td> 
        <td> 
            <img align='center' src="/image/study/llm/lora.png" width="90%"> 
        </td> 
    </tr>
</table>


<h3 id="Low-Rank-Adaptation-LoRA"><a href="#Low-Rank-Adaptation-LoRA" class="headerlink" title="Low-Rank Adaptation (LoRA)"></a><a href="https://arxiv.org/abs/2106.09685">Low-Rank Adaptation (LoRA)</a></h3><ul>
<li>123</li>
</ul>
]]></content>
      <categories>
        <category>study</category>
        <category>llm</category>
      </categories>
      <tags>
        <tag>study.llm</tag>
      </tags>
  </entry>
  <entry>
    <title>CCM for ERC</title>
    <url>/2024/06/17/study/papers/ERC_CCM/</url>
    <content><![CDATA[<h2 align="center"> <a href="https://ieeexplore.ieee.org/abstract/document/10446226">Conversation Clique-based Model for Emotion Recognition in Conversation</a></h2>
<h5 align="center"> If you appreciate our project, please consider giving us a star â­ on GitHub to stay updated with the latest developments.  </h2>

<h4 align="center">

<p>ğŸš€ Welcome to the repo of <a href="https://github.com/jian-projects/ccm"><strong>CCM</strong></a>!</p>
<p>CCM addresses the unimodal ERC task by modeling information with a conversation clique, accepted by ICASSP2024.</p>
<!-- [![ğŸ¤—Hugging Face](https://img.shields.io/badge/ğŸ¤—Hugging_Face-Uni_MoE-yellow)](https://huggingface.co/Uni-MoE) -->
<!-- [![Project Page](https://img.shields.io/badge/Project_Page-Uni_MoE-blue)](https://uni-moe.github.io/) -->
<!-- [![Demo](https://img.shields.io/badge/Demo-Local-orange)](https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs/tree/master?tab=readme-ov-file#-demo-video)  -->
<!-- [![Paper](https://img.shields.io/badge/Paper-arxiv-yellow)](https://arxiv.org/abs/2405.11273) -->

<p><a href="https://scholar.google.com/citations?user=C1PWVBUAAAAJ&hl=zh-CN">Zhongquan Jian</a>, Jiajian Li, <a href="https://scholar.google.com/citations?hl=zh-CN&user=Szz3hSMAAAAJ">Junfeng Yao</a>, <a href="https://dblp.uni-trier.de/pid/99/3203.html">Meihong Wang</a>, <a href="https://dblp.uni-trier.de/pid/130/0742.html">Qingqiang Wu</a></p>
</h4>

<!-- ## ğŸŒŸ Structure

The model architecture of Uni-MoE is shown below. Three training stages contain: 1) Utilize pairs from different modalities and languages to build connectors that map these elements to a unified language space, establishing a foundation for multimodal understanding; 2) Develop modality-specific experts using cross-modal data to ensure deep understanding, preparing for a cohesive multi-expert model; 3) Incorporate multiple trained experts into LLMs and refine the unified multimodal model using the LoRA technique on mixed multimodal data.

<div align=center><img src="https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs/blob/master/model.png" height="100%" width="75%"/></div> -->

<h2 id="âš¡ï¸-Install"><a href="#âš¡ï¸-Install" class="headerlink" title="âš¡ï¸ Install"></a>âš¡ï¸ Install</h2><p>The following instructions are for Linux installation.<br>We would like to recommend the requirements as follows.</p>
<ul>
<li>Python &#x3D;&#x3D; 3.9.16</li>
<li>CUDA Version &gt;&#x3D; 11.7</li>
</ul>
<ol>
<li><p>Clone this repository and navigate to the ccm folder</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git git@github.com:jian-projects/ccm.git<br><span class="hljs-built_in">cd</span> ccm<br></code></pre></td></tr></table></figure>
</li>
<li><p>Install Package</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs Shell">conda create -n ccm python==3.9.16<br>conda activate ccm<br>pip install -r env.txt<br></code></pre></td></tr></table></figure></li>
</ol>
<!-- 3. Replace all the absolute pathnames '/path/to/' with your specific path to the Uni-MoE file
**(Including all the eval_x.py/inference_x.py/train_mem_x.py/data.py/demo.py files and config.json files from the model weights)** -->


<h2 id="ğŸŒˆ-How-to-train-and-inference"><a href="#ğŸŒˆ-How-to-train-and-inference" class="headerlink" title="ğŸŒˆ How to train and inference"></a>ğŸŒˆ How to train and inference</h2><ol>
<li><p>Make sure that all the weights are downloaded and the running environment is set correctly.</p>
</li>
<li><p>run the script:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python run_erc.py<br></code></pre></td></tr></table></figure></li>
</ol>
<!-- 2. run inference scripts [`inference_audio.sh`](https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs/blob/master/Uni_MoE/inference_audio.sh) and [`inference_speech.sh`](https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs/blob/master/Uni_MoE/inference_speech.sh) using ```bash inference_audio.sh``` ```bash inference_speech.sh``` or run the following commands to inference:
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /path/to/Uni_MoE<br>conda activate unimoe<br>python Uni_MoE_audio/inference_all.py<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /path/to/Uni_MoE<br>conda activate unimoe<br>python Uni_MoE_speech/inference_all.py<br></code></pre></td></tr></table></figure>
<p>To launch the online demo ( It is highly recommended to launch the demo with <a href="https://huggingface.co/VictorJsy/Uni-MoE-speech-v1.5">Uni-MoE-speech-v1.5</a> that need the basic parameters of <a href="https://huggingface.co/VictorJsy/Uni-MoE-speech-base-interval">Uni-MoE-speech-base-interval</a>), run:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /path/to/Uni_MoE<br>conda activate unimoe<br>python demo/demo.py<br>python demo/app.py<br>``` --&gt;<br><br><span class="hljs-comment">## Citation</span><br><br>If you find Uni-MoE useful <span class="hljs-keyword">for</span> your research and applications, please cite using this BibTeX:<br>```bibtex<br><br>@INPROCEEDINGS&#123;2024.erc.ccm,<br>  author=&#123;Jian, Zhongquan and Li, Jiajian and Yao, Junfeng and Wang, Meihong and Wu, Qingqiang&#125;,<br>  booktitle=&#123;ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)&#125;, <br>  title=&#123;Conversation Clique-Based Model <span class="hljs-keyword">for</span> Emotion Recognition In Conversation&#125;, <br>  year=&#123;2024&#125;,<br>  volume=&#123;&#125;,<br>  number=&#123;&#125;,<br>  pages=&#123;5865-5869&#125;,<br>  doi=&#123;10.1109/ICASSP48485.2024.10446226&#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>study</category>
        <category>study.paper</category>
      </categories>
      <tags>
        <tag>study.paper</tag>
      </tags>
  </entry>
  <entry>
    <title>Github ä»“åº“é…ç½®</title>
    <url>/2024/06/16/study/skill/Github/</url>
    <content><![CDATA[<h2 align="center"> <a href="https://jianzquan.github.io/">Github ç›¸å…³é…ç½®</a></h2>
<h5 align="center"> 1. æœ¬åœ°ä»“åº“é“¾æ¥Githubä»“åº“ï¼›2. ä»“åº“æ›´æ–°æ“ä½œï¼›3. Githubçš„VsCodeé…ç½® </h2>

<h4 align="center">

<p>Template Reference From <a href="https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs">Uni-MoE</a></p>
<h2 id="ğŸ¨-Github-Config"><a href="#ğŸ¨-Github-Config" class="headerlink" title="ğŸ¨ Github Config"></a>ğŸ¨ Github Config</h2><h3 id="For-Windows"><a href="#For-Windows" class="headerlink" title="For Windows"></a>For Windows</h3><ol>
<li><p>ä¸‹è½½ <a href="https://github.com/git-for-windows/git/releases">Git</a>ï¼Œå¹¶å®‰è£…. ç„¶åï¼Œé…ç½®Gitçš„ç”¨æˆ·å’Œé‚®ç®±:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git config --global user.name xxx<br>git config --global user.email xxxx<br></code></pre></td></tr></table></figure></li>
<li><p>æœ¬åœ°å…¬é’¥å¤åˆ¶åˆ° <a href="https://github.com/settings/keys">Github</a> ä¸Š. åˆ›å»ºä»“åº“ï¼Œå¤åˆ¶ä»“åº“åœ°å€.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">ssh-keygen -t rsa (ç”Ÿæˆå¯†é’¥å¯¹ï¼ŒGitæ“ä½œï¼Œä½ç½®é€šå¸¸åœ¨&#x27;C:\ç”¨æˆ·\ç”¨æˆ·å\.ssh\&#x27;)<br></code></pre></td></tr></table></figure>
</li>
<li><p>é¦–æ¬¡å°†æœ¬åœ°ä»“åº“é“¾æ¥åˆ°Githubä¸Š.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git init (æ–‡ä»¶å¤¹ä¸‹å‡ºç° .git éšè—æ–‡ä»¶)<br>git add README.md<br>git commit -m <span class="hljs-string">&quot;first commit&quot;</span><br>git branch -M main<br>git remote add origin ä»“åº“åœ°å€<br>git push -u origin main<br></code></pre></td></tr></table></figure></li>
</ol>
<h3 id="For-Linux"><a href="#For-Linux" class="headerlink" title="For Linux"></a>For Linux</h3><p>Coming sooon</p>
<h2 id="ğŸ“€-Repository-Update"><a href="#ğŸ“€-Repository-Update" class="headerlink" title="ğŸ“€ Repository Update"></a>ğŸ“€ Repository Update</h2><ol>
<li><p>æ–‡ä»¶æ›´æ–°åï¼Œä¸Šä¼ åˆ°github.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">git add æ–‡ä»¶ (. è¡¨ç¤ºæ·»åŠ æ‰€æœ‰)<br>git commit -m &quot;xxx&quot;<br>git push (-f è¡¨ç¤ºå¼ºåˆ¶è¦†ç›–è¿œç¨‹æ–‡ä»¶)<br></code></pre></td></tr></table></figure>
</li>
<li><p>æ’¤é”€æäº¤çŠ¶æ€.</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><code class="hljs pgsql">git <span class="hljs-keyword">reset</span> HEAD (æ’¤é”€<span class="hljs-keyword">add</span>)<br>git <span class="hljs-keyword">reset</span> <span class="hljs-comment">--soft HEAD^ (ä»…æ’¤é”€commitï¼Œä¿ç•™add)</span><br></code></pre></td></tr></table></figure></li>
</ol>
<h2 id="ğŸŒŸ-VsCode-æœåŠ¡å™¨å…å¯†"><a href="#ğŸŒŸ-VsCode-æœåŠ¡å™¨å…å¯†" class="headerlink" title="ğŸŒŸ VsCode æœåŠ¡å™¨å…å¯†"></a>ğŸŒŸ VsCode æœåŠ¡å™¨å…å¯†</h2><ol>
<li><p>å®‰è£…æ’ä»¶ Remote-SSH</p>
</li>
<li><p>æœ¬åœ°å…¬é’¥å­˜æ”¾åˆ°è¿œç¨‹æœåŠ¡å™¨ç«¯</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh-copy-id ç”¨æˆ·å@æœåŠ¡å™¨åœ°å€ (Windows ä¸Šç”¨ Git æ“ä½œ)<br></code></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>study</category>
        <category>study.skill</category>
      </categories>
      <tags>
        <tag>study.skill</tag>
      </tags>
  </entry>
</search>
